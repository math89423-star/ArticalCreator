import re
import json
import time
from typing import List, Dict, Generator
from openai import OpenAI
from .reference import ReferenceManager
from .word import TextCleaner
import concurrent.futures

def get_rewrite_prompt(thesis_title: str, section_title: str, user_instruction: str, context_summary: str, custom_data: str, original_content: str) -> str:
    
    # 1. åŠ¨æ€ç”Ÿæˆä¸Šä¸‹æ–‡æŒ‡ä»¤
    context_logic_instruction = ""
    
    # å¦‚æœå‰æ–‡å¾ˆå°‘ï¼ˆè¯´æ˜æ˜¯å¼€å¤´éƒ¨åˆ†ï¼‰ï¼ŒæŒ‡ä»¤è¦å¼ºè°ƒâ€œå¼€ç¯‡â€
    if not context_summary or len(context_summary) < 50:
        context_logic_instruction = """
   - **ä½ç½®åˆ¤æ–­**: å½“å‰æ£€æµ‹ä¸º**è®ºæ–‡/ç« èŠ‚çš„èµ·å§‹éƒ¨åˆ†**ã€‚
   - **å†™ä½œé€»è¾‘**: å¿…é¡»**å¼€ç¯‡æ˜ä¹‰**ï¼Œç›´æ¥å¼•å…¥ä¸»é¢˜ï¼Œ**ä¸¥ç¦**ä½¿ç”¨â€œæ‰¿æ¥ä¸Šæ–‡â€ã€â€œç»¼ä¸Šæ‰€è¿°â€ã€â€œå¦‚å‰æ‰€è¿°â€ç­‰è¿‡æ¸¡è¯ã€‚åº”å¥ å®šåŸºè°ƒï¼Œå¼•å‡ºåç»­å†…å®¹ã€‚
"""
    # å¦‚æœæ˜¯â€œç»“è®º/æ€»ç»“â€ç±»ç« èŠ‚ï¼ŒæŒ‡ä»¤è¦å¼ºè°ƒâ€œæ”¶æŸâ€
    elif any(k in section_title for k in ["ç»“è®º", "æ€»ç»“", "å±•æœ›", "ç»“è¯­"]):
        context_logic_instruction = f"""
   - **ä½ç½®åˆ¤æ–­**: å½“å‰ä¸º**ç»“è®º/æ”¶å°¾éƒ¨åˆ†**ã€‚
   - **å‰æ–‡æ‘˜è¦**: "...{context_summary[-300:]}..."
   - **å†™ä½œé€»è¾‘**: å¿…é¡»å¯¹å‰æ–‡ï¼ˆå°¤å…¶æ˜¯æ‘˜è¦ä¸­æåˆ°çš„åˆ†æï¼‰è¿›è¡Œ**é«˜å±‹å»ºç“´çš„æ€»ç»“**ï¼Œè€Œä¸æ˜¯ç®€å•çš„é‡å¤ã€‚è¦å¯¹å…¨æ–‡è¿›è¡Œæ”¶æŸï¼Œå‡åä¸»é¢˜ï¼Œå¹¶å±•æœ›æœªæ¥ã€‚
"""
    # å¦åˆ™é»˜è®¤ä¸ºâ€œä¸­é—´éƒ¨åˆ†â€ï¼ŒæŒ‡ä»¤å¼ºè°ƒâ€œæ‰¿ä¸Šå¯ä¸‹â€
    else:
        context_logic_instruction = f"""
   - **ä½ç½®åˆ¤æ–­**: å½“å‰ä¸º**è®ºæ–‡ä¸­é—´ç« èŠ‚**ã€‚
   - **å‰æ–‡æ‘˜è¦**: "...{context_summary[-500:]}..."
   - **å†™ä½œé€»è¾‘**: å¿…é¡»**ç´§å¯†æ‰¿æ¥**ä¸Šè¿°å‰æ–‡çš„é€»è¾‘æµã€‚
     - å¦‚æœå‰æ–‡åœ¨åˆ†æé—®é¢˜ï¼Œæœ¬æ®µåº”ç»§ç»­æ·±å…¥æˆ–è½¬å‘å¯¹ç­–ï¼›
     - å¦‚æœå‰æ–‡æ˜¯ç†è®ºï¼Œæœ¬æ®µåº”è½¬å‘åº”ç”¨æˆ–å®è¯ã€‚
     - **å¿…é¡»**ä½¿ç”¨æ°å½“çš„å­¦æœ¯è¿‡æ¸¡è¯ï¼ˆå¦‚â€œåŸºäºä¸Šè¿°åˆ†æâ€ã€â€œå…·ä½“è€Œè¨€â€ã€â€œä¸æ­¤åŒæ—¶â€ï¼‰æ¥ç¡®ä¿æ–‡æ°”è´¯é€šï¼Œé¿å…çªå…€ã€‚
"""
    return f"""
# è§’è‰²
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å­¦æœ¯è®ºæ–‡è¯„å®¡ä¸ä¿®æ”¹ä¸“å®¶ï¼Œæ“…é•¿ä¿®æ­£è®ºæ–‡é€»è¾‘ï¼Œç¡®ä¿è®ºè¯ä¸¥å¯†ã€ä¸»é¢˜èšç„¦ã€‚

# æ ¸å¿ƒä»»åŠ¡
ä½ æ­£åœ¨å¯¹è®ºæ–‡ **ã€Š{thesis_title}ã€‹** ä¸­çš„ **â€œ{section_title}â€** ç« èŠ‚è¿›è¡Œé‡å†™ã€‚

# å…³é”®ä¸Šä¸‹æ–‡ä¸é€»è¾‘çº¦æŸ (Context)
1. **å®è§‚ä¸€è‡´æ€§ (é¢˜ç›®)**: 
   - è®ºæ–‡é¢˜ç›®: ã€Š{thesis_title}ã€‹
   - *çº¢çº¿*: ä½ é‡å†™çš„æ‰€æœ‰å†…å®¹ï¼Œå¿…é¡»**ä¸¥æ ¼æœåŠ¡äº**è¿™ä¸ªæ€»æ ‡é¢˜ã€‚**ä¸¥ç¦**æ’°å†™ä¸è¯¥ä¸»é¢˜æ— å…³çš„é€šç”¨åºŸè¯ã€‚
   
2. **å¾®è§‚èšç„¦ (ç« èŠ‚)**: 
   - å½“å‰ç« èŠ‚: â€œ{section_title}â€
   - *çº¢çº¿*: å†…å®¹å¿…é¡»ç²¾å‡†èšç„¦äºè¯¥å°èŠ‚çš„ç‰¹å®šè®ºç‚¹ã€‚
     - å¦‚æœæ ‡é¢˜æ˜¯â€œç°çŠ¶â€ï¼Œå°±åªå†™ç°çŠ¶ï¼Œä¸è¦å†™å¯¹ç­–ï¼›
     - å¦‚æœæ ‡é¢˜æ˜¯â€œåŸå› â€ï¼Œå°±åªå†™åŸå› ï¼Œä¸è¦å†™å½±å“ã€‚
     - **ä¸¥ç¦è¶Šç•Œ**å»å†™å…¶ä»–ç« èŠ‚çš„å†…å®¹ã€‚

3. **ä¸Šä¸‹æ–‡è¿è´¯æ€§ (Flow)**: {context_logic_instruction}

4. **åŸæ–‡åŸºç¡€ (Reference Base)**:
   - **åŸæ–‡å†…å®¹**: 
     ```
     {original_content[:2000]} 
     ```
   - **å¤„ç†ç­–ç•¥**: 
     - ç”¨æˆ·çš„æ„å›¾é€šå¸¸æ˜¯åœ¨**åŸæ–‡åŸºç¡€ä¸Šè¿›è¡Œæ¶¦è‰²ã€ä¿®æ­£æˆ–æ‰©å……**ã€‚
     - **é™¤é**ç”¨æˆ·æŒ‡ä»¤æ˜ç¡®è¦æ±‚â€œå®Œå…¨é‡å†™â€ã€â€œæ¨ç¿»é‡æ¥â€ï¼Œå¦åˆ™è¯·**ä¿ç•™åŸæ–‡çš„æ ¸å¿ƒè§‚ç‚¹å’Œæ•°æ®**ï¼Œé‡ç‚¹ä¼˜åŒ–å…¶è¡¨è¾¾ã€é€»è¾‘ç»“æ„å’Œå­¦æœ¯è§„èŒƒæ€§ã€‚
     - å¦‚æœåŸæ–‡éå¸¸ç®€é™‹ï¼Œè¯·è¿›è¡Œ**æ‰©å†™å’Œæ·±åŒ–**ã€‚


# ç”¨æˆ·ä¿®æ”¹æŒ‡ä»¤ (æœ€é«˜ä¼˜å…ˆçº§ - å¿…é¡»æ»¡è¶³)
{user_instruction}

# ä¸¥æ ¼æ’ç‰ˆä¸å†™ä½œè§„èŒƒ
1. **æ’ç‰ˆæ ¼å¼ (Machine Readable)**:
   - **é¦–è¡Œç¼©è¿›**: è¾“å‡ºçš„**æ¯ä¸€ä¸ªè‡ªç„¶æ®µ**ï¼Œå¼€å¤´å¿…é¡»åŒ…å«**ä¸¤ä¸ªå…¨è§’ç©ºæ ¼** (ã€€ã€€)ã€‚
   - **æ®µé—´è·**: æ®µè½ä¹‹é—´ä½¿ç”¨**å•æ¢è¡Œ** (`\\n`)ï¼Œ**ä¸¥ç¦**ä½¿ç”¨ç©ºè¡Œ (`\\n\\n`)ã€‚
   - **çº¯å‡€è¾“å‡º**: **ä¸¥ç¦**è¾“å‡ºç« èŠ‚æ ‡é¢˜ï¼ˆå¦‚ "### {section_title}"ï¼‰ï¼Œ**ä¸¥ç¦**åŒ…å«â€œå¥½çš„â€ã€â€œæ ¹æ®è¦æ±‚â€ç­‰å¯¹è¯å†…å®¹ã€‚åªè¾“å‡ºæ­£æ–‡ã€‚
2. **æ•°æ®ä½¿ç”¨**:
   - å‚è€ƒæ•°æ®: {custom_data[:500]}...
   - å¦‚æœç”¨æˆ·æä¾›äº†æ•°æ®ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨å¹¶è¿›è¡Œåˆ†æï¼›å¦‚æœæ²¡æœ‰ï¼Œè¯·åŸºäºé€šç”¨å­¦æœ¯é€»è¾‘æ’°å†™ã€‚

è¯·å¼€å§‹é‡å†™ï¼Œç›´æ¥è¾“å‡ºæ­£æ–‡ï¼Œæ³¨æ„æ ¼å¼æ’ç‰ˆã€‚
"""

def get_academic_thesis_prompt(target_words: int, ref_content_list: List[str], current_chapter_title: str, chapter_num: str, has_user_data: bool = False, full_outline: str = "") -> str:
    
    # ------------------------------------------------------------------
    # 1. ç« èŠ‚ä¸“å±é€»è¾‘
    # ------------------------------------------------------------------
    section_rule = ""
    is_cn_abstract = "æ‘˜è¦" in current_chapter_title
    is_en_abstract = "Abstract" in current_chapter_title and "æ‘˜è¦" not in current_chapter_title

    # åˆ¤æ–­æ˜¯å¦ä¸ºéœ€è¦å›¾è¡¨çš„ç« èŠ‚
    # [ä¿®æ”¹ç‚¹1] é€»è¾‘å‡çº§ï¼šå¦‚æœç« èŠ‚ååŒ…å«ç‰¹å®šè¯ OR æŒ‚è½½äº†ç”¨æˆ·æ•°æ®ï¼Œåˆ™å¿…é¡»å¼€å¯å›¾è¡¨
    needs_charts = False
    keywords = ["å®éªŒ", "æµ‹è¯•", "åˆ†æ", "ç»“æœ", "æ•°æ®", "è®¾è®¡", "å®ç°", "éªŒè¯", "Evaluation", "Analysis", "Design"]
    if (chapter_num and any(k in current_chapter_title for k in keywords)) or has_user_data:
        needs_charts = True
    
    # A. æ‘˜è¦
    if is_cn_abstract:
        section_rule = """
**å½“å‰ä»»åŠ¡ï¼šæ’°å†™æ‘˜è¦ä¸å…³é”®è¯**
**çº¢çº¿è§„åˆ™**: 
1. **ä¸¥ç¦è¾“å‡ºæ ‡é¢˜**: ä¸è¦è¾“å‡º "### æ‘˜è¦" æˆ– "### Abstract"ï¼Œç›´æ¥å¼€å§‹å†™æ­£æ–‡ã€‚
2. **ä¸­è‹±å¯¹ç…§**: å…ˆå†™ä¸­æ–‡éƒ¨åˆ†ï¼Œå†å†™è‹±æ–‡éƒ¨åˆ†ã€‚è‹¥æ²¡æœ‰è‹±æ–‡ï¼ˆAbstractï¼‰éƒ¨åˆ†åˆ™ä¸å†™è‹±æ–‡éƒ¨åˆ†ã€‚

**é€»è¾‘ç»“æ„**:
1. **ç ”ç©¶èƒŒæ™¯**: ç®€è¿°èƒŒæ™¯ï¼ˆçº¦50å­—ï¼‰ã€‚
2. **æ–¹æ³•åˆ›æ–°**: åšäº†ä»€ä¹ˆï¼Œç”¨äº†ä»€ä¹ˆæ–¹æ³•ï¼ˆçº¦100å­—ï¼‰ã€‚
3. **å…³é”®å‘ç°**: å¾—åˆ°äº†ä»€ä¹ˆæ•°æ®æˆ–ç»“è®ºï¼ˆçº¦100å­—ï¼‰ã€‚
4. **ç†è®ºè´¡çŒ®**: ä»·å€¼æ˜¯ä»€ä¹ˆï¼ˆçº¦50å­—ï¼‰ã€‚

**æ ¼å¼æ¨¡æ¿**:
   - ç›´æ¥è¾“å‡ºæ‘˜è¦æ­£æ–‡ã€‚
   - æœ€åä¸€è¡Œè¾“å‡ºï¼š**å…³é”®è¯**ï¼šè¯1ï¼›è¯2ï¼›è¯3
"""

    elif is_en_abstract:
        section_rule = """
**Current Task: Write English Abstract & Keywords**
**Requirements**:
1. **Language**: MUST be written in **English** only. No Chinese allowed.
2. **Content**: Translate the logic of a standard academic abstract (Background -> Method -> Results -> Conclusion).
3. **Format**: 
   - Output the abstract body directly.
   - Last line: **Keywords**: Word1; Word2; Word3
"""

    # B. èƒŒæ™¯ä¸æ„ä¹‰
    elif "èƒŒæ™¯" in current_chapter_title:
        section_rule = """
**å½“å‰ä»»åŠ¡ï¼šæ’°å†™ç ”ç©¶èƒŒæ™¯**
**è¦æ±‚**:
1. **çœŸå®æ”¿ç­–**: å¿…é¡»ç»“åˆè¿‘å‡ å¹´ä¸­å›½çœŸå®å­˜åœ¨çš„å›½å®¶æ”¿ç­–ã€æœ€æ–°æ–‡ä»¶ã€é‡å¤§ç›¸å…³äº‹é¡¹ã€‚
2. **æ•°æ®æ”¯æ’‘**: éœ€è¦ä¸€ç‚¹çœŸå®æ•°æ®ä½œä¸ºèƒŒæ™¯æ”¯æ’‘ã€‚
3. **ç¯‡å¹…**: 350å­—å·¦å³ï¼Œä¸æ³›æ³›è€Œè°ˆã€‚
"""
    elif "æ„ä¹‰" in current_chapter_title:
        section_rule = """
**å½“å‰ä»»åŠ¡ï¼šæ’°å†™ç ”ç©¶æ„ä¹‰**
**è¦æ±‚**:
1. **ç†è®ºæ„ä¹‰**: ä¸¥ç¦è¯´â€œå¡«è¡¥äº†ç©ºç™½â€ï¼Œå¿…é¡»è¯´â€œ**ä¸°å¯Œäº†...ç†è®ºæ¡†æ¶**â€æˆ–â€œ**ä¸º...æä¾›äº†å®è¯è¡¥å……**â€ã€‚
2. **å®é™…æ„ä¹‰**: è§£å†³å…·ä½“è¡Œä¸šæˆ–ç¤¾ä¼šç—›ç‚¹ã€‚
3. **ç¯‡å¹…**: 350å­—å·¦å³ã€‚
"""

# C. å›½å†…å¤–ç ”ç©¶ç°çŠ¶
    elif any(k in current_chapter_title for k in ["å›½å†…ç ”ç©¶ç°çŠ¶", "å›½å¤–ç ”ç©¶ç°çŠ¶", "æ–‡çŒ®ç»¼è¿°", "Review", "Status", "æ–‡çŒ®è¿°è¯„", "Literature"]):
        if ref_content_list:
            first_ref = ref_content_list[0]
            if len(ref_content_list) > 1:
                other_refs_prompt = "\n".join([f"{{æ–‡çŒ®{i+2}}}: {ref}" for i, ref in enumerate(ref_content_list[1:])])
            else:
                other_refs_prompt = "æ— åç»­æ–‡çŒ®"
            
            section_rule = f"""
**å½“å‰ä»»åŠ¡ï¼šæ’°å†™ç ”ç©¶ç°çŠ¶ (æ–‡çŒ®ç»¼è¿°)**
**æ ¸å¿ƒç›®æ ‡**ï¼šå°†æä¾›çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨è½¬åŒ–ä¸ºé€»è¾‘é€šé¡ºçš„å­¦æœ¯è¯„è¿°ã€‚

### **å¼•ç”¨è§„èŒƒ**
1.  **ç¦æ­¢å‡ºç°ID**: æ­£æ–‡ä¸­**ç»å¯¹ç¦æ­¢**å‡ºç° "å‚è€ƒæ–‡çŒ®ID"ã€"æ–‡çŒ®1" ç­‰å­—æ ·ã€‚
2.  **å¼•ç”¨æ ¼å¼**: å¿…é¡»ä»æ–‡çŒ®å†…å®¹ä¸­æå–**ä½œè€…**å’Œ**å¹´ä»½**ï¼Œæ ¼å¼ä¸º `ä½œè€…(å¹´ä»½)`ã€‚
    -   *å¼•ç”¨ç¤ºä¾‹*: "å¼ ä¸‰ï¼ˆ2025ï¼‰è®¤ä¸ºå’–å•¡ä¸å¥½å–æ˜¯å› ä¸ºä¸å¤Ÿç”œã€‚"
3.  **ç¦æ­¢æ¨¡ç³Š**: ä¸¥ç¦ä½¿ç”¨ "æŸå­¦è€…"ã€"æœ‰ç ”ç©¶" ç­‰æŒ‡ä»£ä¸æ˜çš„è¯ï¼Œ**å¿…é¡»æŒ‡åé“å§“**ã€‚
4.  **é¡ºåºä¸é¢‘æ¬¡**: å¿…é¡»**ä¸¥æ ¼æŒ‰ç…§åˆ—è¡¨é¡ºåº**é€ä¸€è®ºè¿°ã€‚

### **å†™ä½œé€»è¾‘**
1.  **ç¬¬ä¸€æ®µ (å¯¼è¯­)**: ç®€è¦æ¦‚æ‹¬è¯¥é¢†åŸŸçš„æ€»ä½“å‘å±•è¶‹åŠ¿ï¼ˆçº¦80å­—ï¼‰ã€‚
2.  **ç¬¬äºŒæ®µ (æ ¸å¿ƒç»¼è¿°)**: 
    -   **é¦–æ¡è¯¦è¿°**: é’ˆå¯¹ **{{æ–‡çŒ®1}}** ({first_ref}) è¿›è¡Œè¯¦ç»†è¯„è¿°ï¼ˆçº¦150å­—ï¼‰ã€‚å†™æ˜ï¼šä½œè€…+å¹´ä»½+æ ¸å¿ƒè´¡çŒ®+å±€é™æ€§ã€‚
    -   **åç»­ä¸²è”**: ä¾æ¬¡å¯¹ **{{æ–‡çŒ®2}}** åŠåç»­æ–‡çŒ®è¿›è¡Œè¯„è¿°ã€‚
        -   ä½¿ç”¨è¿æ¥è¯ï¼ˆå¦‚"ä¸ä¹‹ç±»ä¼¼"ã€"ç„¶è€Œ"ã€"åœ¨æ­¤åŸºç¡€ä¸Š"ï¼‰å°†ä¸åŒæ–‡çŒ®é€»è¾‘ä¸²è”ã€‚
3.  **ç¬¬ä¸‰æ®µ (è¯„è¿°)**: æ€»ç»“ä¸Šè¿°æ–‡çŒ®çš„å…±åŒä¸è¶³ï¼Œå¼•å‡ºæœ¬ç ”ç©¶çš„åˆ‡å…¥ç‚¹ã€‚

**å¾…ç»¼è¿°çš„æ–‡çŒ®åˆ—è¡¨ (è¯·ä»ä¸­æå–ä¿¡æ¯)**:
- {{æ–‡çŒ®1}}: {first_ref}
{other_refs_prompt}
"""
        else:
            section_rule = "**å½“å‰ä»»åŠ¡ï¼šæ’°å†™ç ”ç©¶ç°çŠ¶**\nè¯·åŸºäºé€šç”¨å­¦æœ¯çŸ¥è¯†æ’°å†™ï¼Œä¿æŒæ€»åˆ†æ€»ç»“æ„ï¼Œå¼•ç”¨çœŸå®å­˜åœ¨çš„ç»å…¸æ–‡çŒ®ã€‚"

    # D. æ–‡çŒ®è¿°è¯„
    elif "è¿°è¯„" in current_chapter_title:
        section_rule = """
**å½“å‰ä»»åŠ¡ï¼šæ’°å†™æ–‡çŒ®è¿°è¯„**
**å†™ä½œè¦æ±‚**: 
1. **ä¸å¼•ç”¨**: æ­¤éƒ¨åˆ†ä¸éœ€è¦å¼•ç”¨å…·ä½“æ–‡çŒ®ã€‚
2. **å†…å®¹**: æ€»ç»“å‰æ–‡æ–‡çŒ®çš„ä¸è¶³ï¼Œéœ€è¦å¯¹å…¨éƒ¨æ–‡çŒ®åšå‡ºæ€»ç»“ï¼Œå½’çº³è¿™äº›æ–‡çŒ®å¸¦æ¥çš„å¯ç¤ºï¼Œå¯¹æœ¬ç ”ç©¶çš„å½±å“ï¼Œæœ¬ç ”ç©¶èƒ½ä»æ–‡çŒ®ä¸­å€Ÿé‰´å’Œå­¦ä¹ åˆ°çš„å†…å®¹ï¼Œé˜è¿°ç ”ç©¶çš„ä¸è¶³ï¼Œä»¥åŠéœ€è¦ä¸°å¯Œçš„å†…å®¹ç­‰ç­‰ã€‚
3. **å­—æ•°ä¸ç¯‡å¹…è¦æ±‚**: åªå†™ä¸€ä¸ªæ®µè½ï¼Œçº¦300å­—å·¦å³ã€‚
"""

    # E. ç ”ç©¶å†…å®¹
    elif "ç ”ç©¶å†…å®¹" in current_chapter_title and "æ–¹æ³•" not in current_chapter_title:
        section_rule = """
**å½“å‰ä»»åŠ¡ï¼šæ’°å†™ç ”ç©¶å†…å®¹**
**æ ¼å¼**: åˆ†æ®µå¼å›ç­”ã€‚
1. **å¯¼è¯­**: â€œæœ¬ç ”ç©¶ä¸»è¦ç ”ç©¶...ï¼Œå…·ä½“å†…å®¹å¦‚ä¸‹ï¼šâ€
2. **åˆ†ç« èŠ‚**: 
   - â€œç¬¬ä¸€éƒ¨åˆ†ï¼Œç»ªè®ºã€‚ä¸»è¦é˜è¿°...â€
   - â€œç¬¬äºŒéƒ¨åˆ†ï¼Œ...ã€‚åˆ†æäº†...â€
   - ...
**è¦æ±‚**: æ ¸å¿ƒç« èŠ‚è§£é‡Šçº¦200å­—ï¼Œè¯¦ç•¥å¾—å½“ã€‚
"""

    # F. ç ”ç©¶æ–¹æ³•
    elif "ç ”ç©¶æ–¹æ³•" in current_chapter_title:
        section_rule = """
**å½“å‰ä»»åŠ¡ï¼šæ’°å†™ç ”ç©¶æ–¹æ³•**
**æ ¼å¼**: åˆ†ç‚¹å›ç­”ï¼Œå¿…é¡»æ ‡åºå· (1. 2. 3.)ã€‚
**å¿…é€‰æ–¹æ³• (æŒ‰éœ€é€‰æ‹©)**:
1. **æ–‡çŒ®ç ”ç©¶æ³•**: (å¦‚æœ‰å‚è€ƒæ–‡çŒ®åˆ™å¿…é€‰)
2. **æ•°æ®åˆ†ææ³•**: (å¦‚æœ‰æ•°æ®åˆ†æåˆ™å¿…é€‰)
3. **å®è¯ç ”ç©¶æ³•/æ¡ˆä¾‹åˆ†ææ³•**: (æ ¹æ®é¢˜ç›®åˆ¤æ–­)
**è¦æ±‚**: ç»“åˆè®ºæ–‡ä¸»é¢˜è§£é‡Šä¸ºä»€ä¹ˆç”¨è¿™ä¸ªæ–¹æ³•ã€‚
"""

    # G. é€šç”¨æ­£æ–‡
    else:
        section_rule = """
**å½“å‰ä»»åŠ¡ï¼šæ’°å†™æ­£æ–‡åˆ†æ**
1. **é€»è¾‘ä¸»å¯¼**: æ ¸å¿ƒæ˜¯åˆ†ææ€è·¯ã€‚
2. **æ·±åº¦è®ºè¿°**: æ¯ä¸€æ®µéƒ½è¦æœ‰è§‚ç‚¹ã€æœ‰è®ºæ®ï¼ˆæ•°æ®æˆ–ç†è®ºï¼‰ã€æœ‰ç»“è®ºã€‚

"""

    # ------------------------------------------------------------------
    # 2. å¼•ç”¨æŒ‡ä»¤
    # ------------------------------------------------------------------
    ref_instruction = ""
    
    # å®šä¹‰å±äºâ€œç»¼è¿°/ç°çŠ¶â€çš„å…³é”®è¯
    review_keywords = ["å›½å†…ç ”ç©¶ç°çŠ¶", "å›½å¤–ç ”ç©¶ç°çŠ¶", "æ–‡çŒ®ç»¼è¿°", "Review", "Status", "æ–‡çŒ®è¿°è¯„", "Literature"]
    is_review_chapter = any(k in current_chapter_title for k in review_keywords)

    if ref_content_list and is_review_chapter:
        # åªæœ‰åœ¨ç»¼è¿°ç« èŠ‚ï¼Œæ‰å¼ºåˆ¶è¦æ±‚å¼•ç”¨
        ref_instruction = f"""
### **ç­–ç•¥D: å¼•ç”¨æ‰§è¡Œ (Token Strategy)**
æœ¬ç« èŠ‚**å¿…é¡»**å¼•ç”¨åˆ†é…çš„æ–‡çŒ®ã€‚
1.  **ä¸è¦ç”Ÿæˆåºå·**: ä¸è¦å†™ [1] [2]ã€‚
2.  **æ’å…¥æ ‡è®°**: åœ¨æåˆ°æ–‡çŒ®è§‚ç‚¹æ—¶ï¼Œå¿…é¡»æ’å…¥ **`[REF]`** æ ‡è®°ã€‚
3.  **æ•°é‡**: å¿…é¡»æ’å…¥ {len(ref_content_list)} ä¸ª `[REF]` æ ‡è®°ã€‚
4.  **å…³è”**: å³ä½¿æ–‡çŒ®ä¸å®Œå…¨ç›¸å…³ï¼Œä¹Ÿè¦ç”¨â€œæ­¤å¤–ï¼Œä¹Ÿæœ‰ç ”ç©¶æŒ‡å‡º...â€å¼ºè¡Œå…³è”ï¼Œ**è‡ªåœ†å…¶è¯´**ã€‚
"""
    else:
        # å…¶ä»–ç« èŠ‚ï¼ˆå¦‚ç»ªè®ºã€ç†è®ºã€å®è¯ã€ç»“è®ºç­‰ï¼‰ä¸¥ç¦å¼•ç”¨
        ref_instruction = """
### **ç­–ç•¥D: å¼•ç”¨ç¦ä»¤ (Citation Ban)**
**æœ¬ç« èŠ‚ä¸¥ç¦å¼•ç”¨å‚è€ƒæ–‡çŒ®åˆ—è¡¨**ã€‚
1.  **ç»å¯¹ç¦æ­¢**ä½¿ç”¨ `[REF]` æ ‡è®°ã€‚
2.  **ç»å¯¹ç¦æ­¢**æåŠâ€œæ–‡çŒ®[x]â€ã€â€œæŸå­¦è€…æŒ‡å‡ºâ€ã€â€œå·²æœ‰ç ”ç©¶è¡¨æ˜â€ç­‰ç»¼è¿°æ€§è¯­è¨€ã€‚
3.  è¯·å®Œå…¨åŸºäº**ç†è®ºæ¨å¯¼**ã€**ç”¨æˆ·æä¾›çš„æ•°æ®**æˆ–**é€šç”¨å­¦æœ¯çŸ¥è¯†**è¿›è¡Œè®ºè¿°ã€‚
"""

    # å…è®¸çš„å­—æ•°æ³¢åŠ¨èŒƒå›´
    min_words = int(target_words * 0.85)
    max_words = int(target_words * 1.15)
    word_count_strategy = f"""
1.  **ç›®æ ‡å­—æ•°**: **{target_words} å­—**ã€‚
2.  **å¼ºåˆ¶èŒƒå›´**: è¾“å‡ºå†…å®¹å¿…é¡»ä¸¥æ ¼æ§åˆ¶åœ¨ **{min_words} ~ {max_words} å­—**ä¹‹é—´ã€‚

"""
    if is_en_abstract or is_cn_abstract:
        word_count_strategy = "å­—æ•°éµå¾ªæ‘˜è¦æ ‡å‡†ã€‚"
    # ----------------- ç­–ç•¥F: Python ç»˜å›¾ -----------------
    visuals_instruction = ""
    
    # åŠ¨æ€å›¾è¡¨æŒ‡ä»¤ï¼šå¦‚æœæ˜¯ç”¨æˆ·æ•°æ®ï¼Œå¼ºåˆ¶å¯è§†åŒ–
    user_data_chart_instruction = ""
    if has_user_data:
        user_data_chart_instruction = """
        -   **ç”¨æˆ·æ•°æ®å¼ºåˆ¶å¯è§†åŒ– (Mandatory)**: 
            -   æ£€æµ‹åˆ°ã€ç”¨æˆ·æä¾›çš„çœŸå®æ•°æ®ã€‘ã€‚**å¿…é¡»**å°†è¯¥æ•°æ®è½¬åŒ–ä¸ºå¯è§†åŒ–çš„**è¡¨æ ¼**æˆ–**Pythonç»Ÿè®¡å›¾**ã€‚
            -   **ä¸¥ç¦**ä»…ä»…åœ¨æ­£æ–‡ä¸­ç”¨æ–‡å­—ç½—åˆ—æ•°å­—ï¼Œå¿…é¡»é…åˆå›¾è¡¨å±•ç¤ºã€‚
            -   å¦‚æœæ˜¯æ—¶é—´åºåˆ—æ•°æ® -> ç”»æŠ˜çº¿å›¾ï¼›å¦‚æœæ˜¯å æ¯” -> ç”»é¥¼å›¾ï¼›å¦‚æœæ˜¯å¯¹æ¯” -> ç”»æŸ±çŠ¶å›¾ã€‚
        -   **å»é‡æ£€æŸ¥**: ä¸¥ç¦é‡å¤ç”Ÿæˆç›¸åŒå†…å®¹çš„å›¾è¡¨ã€‚å¦‚æœæ•°æ®å·²ç”»è¿‡ï¼Œè¯·ä½¿ç”¨â€œ**å¦‚å›¾Xæ‰€ç¤º**â€å¼•ç”¨å¹¶åˆ†æã€‚
        -  **æ•°æ®æºæ‹“å±•**: 
                -   **ä¼˜å…ˆ**: ä½¿ç”¨ã€ç”¨æˆ·æä¾›çš„çœŸå®æ•°æ®ã€‘ã€‚
                -   **è¡¥å……**: å¦‚æœç”¨æˆ·æ•°æ®ä¸è¶³ä»¥æ”¯æ’‘å½“å‰è®ºç‚¹ï¼ˆå¦‚ç»´åº¦ä¸å¤Ÿã€æ—¶é—´è·¨åº¦ä¸è¶³ï¼‰ï¼Œ**ç«‹å³ä½¿ç”¨ã€è”ç½‘æ£€ç´¢è¡¥å……æ•°æ®ã€‘**è¿›è¡Œç»˜å›¾ï¼Œä¸è¦å¼ºè¡Œå¤ç”¨ä¸ç›¸å…³çš„ç”¨æˆ·æ•°æ®ã€‚
"""

    if needs_charts:
        visuals_instruction = f"""
### **ç­–ç•¥F: å›¾è¡¨ä¸æ•°æ®å¯è§†åŒ– (Python & Tables)**
**æœ¬ç« èŠ‚å¿…é¡»åŒ…å«å›¾è¡¨**ã€‚{user_data_chart_instruction}
è¯·æŒ‰ä»¥ä¸‹è§„èŒƒç”Ÿæˆï¼š
**å†³ç­–è§„åˆ™ (Decision Rules) - ä¸¥ç¦å†—ä½™**:
1.  **äºŒé€‰ä¸€åŸåˆ™**: é’ˆå¯¹åŒä¸€ç»„æ•°æ®ï¼Œ**åªèƒ½**é€‰æ‹©â€œMarkdownè¡¨æ ¼â€**æˆ–è€…**â€œPythonç»Ÿè®¡å›¾â€å…¶ä¸­ä¸€ç§å½¢å¼ï¼Œ**ä¸¥ç¦**å¯¹åŒä¸€æ•°æ®æ—¢ç”»å›¾åˆåˆ¶è¡¨ã€‚
    -   **é€‰è¡¨æ ¼**: å½“æ•°æ®éœ€è¦å±•ç¤ºç²¾ç¡®æ•°å€¼ã€æˆ–è€…åŒ…å«å¤§é‡æ–‡å­—åˆ†ç±»æ—¶ã€‚
    -   **é€‰ç”»å›¾**: å½“æ•°æ®ä¾§é‡äºå±•ç¤º**è¶‹åŠ¿**ï¼ˆæŠ˜çº¿å›¾ï¼‰ã€**å¯¹æ¯”**ï¼ˆæŸ±çŠ¶å›¾ï¼‰æˆ–**å æ¯”**ï¼ˆé¥¼å›¾ï¼‰æ—¶ã€‚

2.  **è¡¨æ ¼**:
    -   ä½¿ç”¨ Markdown è¡¨æ ¼è¯­æ³•ç»˜åˆ¶ä¸‰çº¿è¡¨ã€‚
    -   **è¡¨å**: åœ¨è¡¨æ ¼**ä¸Šæ–¹**ï¼Œæ ¼å¼ï¼š`**è¡¨{chapter_num}.X è¡¨å**`ã€‚

3.  **ç»Ÿè®¡å›¾ (Python Matplotlib) - æ ¸å¿ƒè¦æ±‚**:
    -   è¯·ç¼–å†™ä¸€æ®µ**æ ‡å‡†ã€æ— é”™ã€å¯ç›´æ¥è¿è¡Œçš„ Python ä»£ç **ã€‚
    -   **ä»£ç å—æ ¼å¼**: ä½¿ç”¨ ` ```python ` åŒ…è£¹ã€‚
    -   **å…³é”®è¦æ±‚ (CRITICAL)**: 
        -   **æ•°æ®ä¸€è‡´æ€§ (æœ€é«˜ä¼˜å…ˆçº§)**: å›¾è¡¨æ•°æ®å¿…é¡»**ä¸¥æ ¼æ¥æºäºæ­£æ–‡è®ºè¿°**ã€‚ä¸¥ç¦æ­£æ–‡è¯´â€œå¢é•¿20%â€è€Œå›¾è¡¨æ˜¾ç¤ºâ€œå¢é•¿50%â€ã€‚å›¾è¡¨æ˜¯æ­£æ–‡æ•°æ®çš„â€œé•œåƒâ€ï¼Œ**ç»å¯¹ç¦æ­¢**æé€ ä¸æ­£æ–‡æ— å…³çš„æ•°æ®é›†ã€‚
        -   **ç»Ÿè®¡å›¾é€‰å‹è§„èŒƒ**: å¿…é¡»æ ¹æ®æ•°æ®é€»è¾‘é€‰æ‹©æœ€æ ‡å‡†çš„ç»Ÿè®¡å›¾ï¼š
            -   **è¶‹åŠ¿åˆ†æ** (éšæ—¶é—´å˜åŒ–) -> **æŠ˜çº¿å›¾ (Line Chart)**
            -   **ä¸åŒé¡¹å¯¹æ¯”** (å¤§å°æ¯”è¾ƒ) -> **æŸ±çŠ¶å›¾ (Bar Chart)**
            -   **ç»“æ„å æ¯”** (ä»½é¢åˆ†æ) -> **é¥¼å›¾ (Pie Chart)** æˆ– **ç¯å½¢å›¾**
            -   **ç›¸å…³æ€§/åˆ†å¸ƒ** -> **æ•£ç‚¹å›¾ (Scatter)** æˆ– **ç®±çº¿å›¾ (Boxplot)**
            -   *ä¸¥ç¦ä½¿ç”¨éç»Ÿè®¡å­¦çš„â€œç¤ºæ„å›¾â€æˆ–æ— æ„ä¹‰çš„å›¾å½¢ã€‚*
        -   **åº“å¯¼å…¥**: å¿…é¡»åœ¨ä»£ç å¼€å¤´æ˜¾å¼å¯¼å…¥ï¼š`import matplotlib.pyplot as plt`, `import seaborn as sns`, `import pandas as pd`, `import numpy as np`ã€‚
        -   **æ•°æ®è‡ªåŒ…å«**: æ•°æ®å¿…é¡»åœ¨ä»£ç å†…éƒ¨å®Œæ•´å®šä¹‰ï¼ˆä½¿ç”¨ DataFrame æˆ–å­—å…¸ï¼‰ï¼Œ**ä¸¥ç¦**è¯»å–å¤–éƒ¨æ–‡ä»¶ã€‚
        -   **æ ¼å¼è§„èŒƒ**: ä¸¥ç¦ä½¿ç”¨å…¨è§’ç©ºæ ¼ï¼ˆ\\u3000ï¼‰æˆ–ä¸é—´æ–­ç©ºæ ¼ï¼ˆNBSPï¼‰ï¼Œå¿…é¡»ä½¿ç”¨æ ‡å‡†ç©ºæ ¼ç¼©è¿›ã€‚
        -   **å­—ä½“è®¾ç½®**: å¿…é¡»åŒ…å« `plt.rcParams['font.sans-serif'] = ['SimHei']`,  `font = FontProperties(fname=r'C:\Windows\Fonts\simhei.ttf', size=12)`, `plt.rcParams['axes.unicode_minus'] = False`, è§£å†³ä¸­æ–‡ä¹±ç ï¼Œå¹¶ä¸”æ¯ä¸ªæ–‡æœ¬å…ƒç´ æ˜¾å¼æŒ‡å®šå­—ä½“ã€‚
        -   **ç¾è§‚æ€§**: ä½¿ç”¨ `sns.set_theme(style="whitegrid")`ï¼Œé…è‰²éœ€ç¬¦åˆå­¦æœ¯è§„èŒƒï¼ˆå¦‚æ·±è“ã€æ·±çº¢ã€ç°åº¦ï¼‰ï¼Œé¿å…è¿‡äºèŠ±å“¨ã€‚
        -   **è¾“å‡º**: æœ€å**ä¸éœ€è¦** `plt.show()`ã€‚
    -   **å›¾å**: åœ¨ä»£ç å—**ä¸‹æ–¹**ï¼Œæ ¼å¼ï¼š`**å›¾{chapter_num}.X å›¾å**`ã€‚

4.  **å›¾æ–‡äº’åŠ¨**: 
    -   æ­£æ–‡è®ºè¿°æ•°æ®æ—¶ï¼Œå¿…é¡»æåŠ â€œ**å¦‚å›¾{chapter_num}.Xæ‰€ç¤º**â€ æˆ– â€œ**å¦‚è¡¨{chapter_num}.Xæ‰€ç¤º**â€ã€‚
    -   å›¾è¡¨ç”Ÿæˆåï¼Œå¿…é¡»åœ¨æ­£æ–‡ä¸­å¯¹å›¾è¡¨åæ˜ çš„**è¶‹åŠ¿ã€æ‹ç‚¹æˆ–å¼‚å¸¸å€¼**è¿›è¡Œç®€è¦åˆ†æï¼Œå®ç°å›¾æ–‡äº’è¯ã€‚
"""
    else:
        visuals_instruction = "### **ç­–ç•¥F: å›¾è¡¨ç¦ä»¤**\n**ä¸¥ç¦ç”Ÿæˆä»»ä½•å›¾è¡¨ã€‚**"

    return f"""
# è§’è‰²
ä½ ç°åœ¨æ‰®æ¼”ä¸€ä½**ä¸¥è°¨çš„å­¦æœ¯å¯¼å¸ˆ**ï¼Œè¾…åŠ©å­¦ç”Ÿæ’°å†™æ¯•ä¸šè®ºæ–‡ã€‚
ä»»åŠ¡ï¼šä¸¥æ ¼éµå¾ªç‰¹å®šçš„å†™ä½œæ¨¡æ¿ï¼Œä¿è¯å­¦æœ¯è§„èŒƒï¼Œ**ç»ä¸å¤¸å¤§æˆæœ**ï¼Œ**å›¾æ–‡å¹¶èŒ‚**ã€‚

### **ç­–ç•¥A: æ ¼å¼ä¸æ’ç‰ˆ**
1.  **æ®µè½ç¼©è¿›**: **æ‰€æœ‰æ®µè½å¼€å¤´å¿…é¡»åŒ…å«ä¸¤ä¸ªå…¨è§’ç©ºæ ¼ï¼ˆã€€ã€€ï¼‰**ã€‚
2.  **ç¦ç”¨åˆ—è¡¨**: ä¸¥ç¦ä½¿ç”¨ Markdown åˆ—è¡¨ï¼Œå¿…é¡»å†™æˆè¿è´¯æ®µè½ï¼ˆç ”ç©¶æ–¹æ³•é™¤å¤–ï¼‰ã€‚

### **ç­–ç•¥B: æ•°æ®ä¸è°¦æŠ‘æ€§ (CRITICAL)**
1.  **å­—ä½“è§„èŒƒ**: **æ‰€æœ‰æ•°å­—ã€å­—æ¯ã€æ ‡ç‚¹å¿…é¡»ä½¿ç”¨åŠè§’å­—ç¬¦ (Half-width)**ã€‚
2.  **æ•°æ®ä¼˜å…ˆçº§**: 
    -   **æœ€é«˜ä¼˜å…ˆçº§**: å¦‚æœè¾“å…¥ä¸­åŒ…å«ã€ç”¨æˆ·æä¾›çš„çœŸå®æ•°æ®ã€‘ï¼Œå¿…é¡»**æ— æ¡ä»¶åŸºäºè¯¥æ•°æ®**è¿›è¡Œåˆ†æä¸åˆ¶å›¾ï¼Œ**ä¸¥ç¦ç¯¡æ”¹æ•°å€¼**ã€‚
    -   **æ¬¡çº§æ¥æº**: ä»…åœ¨ç”¨æˆ·æœªæä¾›æ•°æ®æ—¶ï¼Œæ‰ä½¿ç”¨ã€è”ç½‘æ£€ç´¢äº‹å®ã€‘æˆ–é€šç”¨å­¦æœ¯çŸ¥è¯†ã€‚
3.  **ä¸¥ç¦å¤¸å¤§**: 
    -   **ç¦æ­¢**: â€œå¡«è¡¥ç©ºç™½â€ã€â€œå›½å†…é¦–åˆ›â€ã€â€œå®Œç¾è§£å†³â€ã€‚
    -   **å¿…é¡»ç”¨**: â€œä¸°å¯Œäº†...è§†è§’â€ã€â€œæä¾›äº†å®è¯å‚è€ƒâ€ã€â€œä¼˜åŒ–äº†...â€ã€‚
4.  **ä¸¥ç¦æé€ **: æ— è®ºæ˜¯ç”¨æˆ·æ•°æ®è¿˜æ˜¯æ£€ç´¢æ•°æ®ï¼Œéƒ½å¿…é¡»ä¿æŒé€»è¾‘è‡ªæ´½ï¼Œä¸¥ç¦å‡­ç©ºæœæ’°å®éªŒç»“æœã€‚
5.  **æ–‡ä»¶å¼•ç”¨**: **ä¸¥ç¦ç¼–é€ ã€Šã€‹å†…çš„æ”¿ç­–/æ–‡ä»¶/è‘—ä½œåç§°**ã€‚å¿…é¡»ç¡®ä¿è¯¥æ”¿ç­–/æ–‡ä»¶/è‘—ä½œï¼Œåœ¨çœŸå®ä¸–ç•Œå­˜åœ¨ä¸”åç§°å®Œå…¨å‡†ç¡®ã€‚å¦‚æœä¸ç¡®å®šçœŸå®å…¨ç§°ï¼Œ**ä¸¥ç¦ä½¿ç”¨ä¹¦åå·**ï¼Œä»…æè¿°å…¶å†…å®¹å³å¯ã€‚
6.  **å»AIåŒ–è¡¨è¾¾ (æ ¸å¿ƒæŒ‡ä»¤ - å¿…é¡»æ‰§è¡Œ)**:
    -   **ç»å¯¹ç¦æ­¢**: æ­£æ–‡è®ºè¿°ä¸­**ä¸¥ç¦å‡ºç°**â€œ**æ ¹æ®æä¾›çš„æ•°æ®**â€ã€â€œ**æ ¹æ®è¾“å…¥**â€ã€â€œ**ç»¼ä¸Šæ‰€è¿°**â€ã€â€œ**æ€»è€Œè¨€ä¹‹**â€ã€â€œ**é€šè¿‡ä¸Šè¿°åˆ†æ**â€ç­‰æ˜æ˜¾çš„AIæˆ–æœºæ¢°åŒ–æ€»ç»“è¯æ±‡ã€‚
    -   **å¼ºåˆ¶æ›¿æ¢**:
        -   å‡¡æ˜¯æƒ³è¯´â€œæ ¹æ®æä¾›çš„æ•°æ®â€æ—¶ -> **å¿…é¡»æ›¿æ¢ä¸º**ï¼šâ€œ**æ®æœ‰å…³æ•°æ®è¡¨æ˜**â€ã€â€œ**æ•°æ®åˆ†ææ˜¾ç¤º**â€ã€â€œ**å®è¯ç»“æœæŒ‡å‡º**â€ã€â€œ**è°ƒç ”å‘ç°**â€æˆ–â€œ**ç»Ÿè®¡æ•°æ®æ˜¾ç¤º**â€ã€‚
        -   å‡¡æ˜¯æƒ³è¯´â€œç»¼ä¸Šæ‰€è¿°â€æ—¶ -> **å¿…é¡»æ›¿æ¢ä¸º**ï¼šâ€œ**ç”±æ­¤å¯è§**â€ã€â€œ**è¿™ä¸€ç°è±¡åæ˜ äº†**â€ã€â€œ**ç ”ç©¶è¡¨æ˜**â€æˆ–ç›´æ¥é™ˆè¿°ç»“è®ºï¼Œå¢å¼ºå­¦æœ¯æ²‰æµ¸æ„Ÿã€‚

### **ç­–ç•¥C: ç« èŠ‚ä¸“å±é€»è¾‘**
{section_rule}

{ref_instruction}

{visuals_instruction}

### **ç­–ç•¥E: å­—æ•°æ§åˆ¶**
{word_count_strategy}
**æ‰©å†™æŠ€å·§**: å¦‚æœå­—æ•°ä¸è¶³ï¼Œè¯·å¯¹æ ¸å¿ƒæ¦‚å¿µè¿›è¡Œå®šä¹‰æ‰©å±•ï¼Œæˆ–å¢åŠ â€œä¸¾ä¾‹è¯´æ˜â€ã€â€œå¯¹æ¯”åˆ†æâ€ã€â€œç†è®ºæ”¯æ’‘â€ç­‰ç¯èŠ‚ï¼Œ**ä¸¥ç¦**é€šè¿‡é‡å¤åºŸè¯å‡‘å­—æ•°ã€‚

### **ç­–ç•¥G: ç»“æ„ä¸è¾¹ç•Œæ§åˆ¶ (CRITICAL - ç»å¯¹ç¦æ­¢é¡¹)**
1.  **ç¦æ­¢è‡ªæ‹Ÿæ ‡é¢˜**: è¾“å‡ºå†…å®¹**ä¸¥ç¦åŒ…å«**ä»»ä½• Markdown æ ‡é¢˜ç¬¦å·ï¼ˆ#ã€##ã€###ï¼‰ã€‚
    -   é”™è¯¯ç¤ºä¾‹ï¼š`### 1.1 èƒŒæ™¯åˆ†æ`
    -   æ­£ç¡®æ“ä½œï¼šç›´æ¥å¼€å§‹å†™èƒŒæ™¯åˆ†æçš„**æ­£æ–‡æ®µè½**ã€‚
2.  **ç¦æ­¢è¶Šç•Œ**: **ä¸¥ç¦**æ’°å†™ä¸‹ä¸€ä¸ªç« èŠ‚çš„å†…å®¹ã€‚åªå…³æ³¨å½“å‰ç« èŠ‚ï¼š**â€œ{current_chapter_title}â€**ã€‚
3.  **ç¦æ­¢åˆ†ç‚¹**: é™¤éæ˜¯â€œç ”ç©¶æ–¹æ³•â€ç« èŠ‚ï¼Œå¦åˆ™ä¸¥ç¦ä½¿ç”¨ `1.` `2.` æˆ– `*` è¿›è¡Œç½—åˆ—ã€‚ä½¿ç”¨å­¦æœ¯é€»è¾‘è¿æ¥è¯ï¼Œä¾‹å¦‚ï¼šâ€œå€¼å¾—æ³¨æ„çš„æ˜¯â€ã€â€œä¸æ­¤åŒæ—¶â€ã€â€œè¿›ä¸€æ­¥åˆ†æè¡¨æ˜â€ã€â€œä»...è§’åº¦æ¥çœ‹â€ã€â€œç”±æ­¤æ¨å¯¼â€ç­‰ï¼Œæˆ–é€šè¿‡å› æœé€»è¾‘è‡ªç„¶è¡”æ¥ã€‚
4.  **ä¸¥ç¦å…ƒæ•°æ®æ ‡è¯†**: 
    -   **ç»å¯¹ç¦æ­¢**åœ¨æ­£æ–‡ä¸­è¾“å‡ºâ€œ(ç©ºä¸¤æ ¼)â€ã€â€œ(æ¥ä¸Šæ–‡)â€ã€â€œ(æ­¤å¤„æ’å…¥...)â€ç­‰æ‹¬å·è¯´æ˜æ–‡å­—ã€‚
    -   **ç¦æ­¢**ä½¿ç”¨çœç•¥å·(...)ä½œä¸ºæ®µè½å¼€å¤´ã€‚ç›´æ¥å¼€å§‹è®ºè¿°å³å¯ã€‚

### **ç­–ç•¥H: å…¨å±€è§†é‡ä¸å®šä½ (Global Structure)**
ä¸ºäº†ä¿è¯é€»è¾‘è¿è´¯ï¼Œè¯·å‚è€ƒä»¥ä¸‹çš„**å…¨æ–‡å¤§çº²**ï¼Œæ˜ç¡®ä½ å½“å‰çš„å†™ä½œä½ç½®.
{full_outline}


è¯·å¼€å§‹å†™ä½œã€‚
"""

def get_word_distribution_prompt(total_words: int, outline_text: str) -> str:
    return f"""
# è§’è‰²
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å­¦æœ¯è®ºæ–‡ç¼–è¾‘ã€‚

# ä»»åŠ¡
æ ¹æ®ç”¨æˆ·æä¾›çš„è®ºæ–‡å¤§çº²ï¼Œè¿›è¡Œä¸¤é¡¹è§„åˆ’ï¼š
1. **å­—æ•°åˆ†é…**: å°†æ€»å­—æ•° **{total_words}å­—** åˆç†åˆ†é…ç»™å„ç« èŠ‚ã€‚
2. **æ•°æ®ç­–ç•¥**: åˆ¤æ–­è¯¥ç« èŠ‚æ˜¯å¦éœ€è¦**çœŸå®æ•°æ®æ”¯æ’‘**ï¼ˆåŒ…æ‹¬ç”¨æˆ·ä¸Šä¼ çš„æ•°æ®æˆ–è”ç½‘æœç´¢çš„å®è§‚æ•°æ®ï¼‰ã€‚

# è§„åˆ’åŸåˆ™
1. **å­—æ•°æƒé‡**:
   - æ ¸å¿ƒç« èŠ‚ (å®è¯/åˆ†æ/è®¾è®¡) å  60%-70%ã€‚
   - æ¬¡è¦ç« èŠ‚ (ç»¼è¿°/ç†è®º) å  20%-30%ã€‚
   - è¾…åŠ©ç« èŠ‚ (æ‘˜è¦/ç»“è®º) å  10%-15%ã€‚
   - **æ€»å­—æ•°çº¦æŸ**: æ‰€æœ‰ç« èŠ‚åˆ†é…çš„å­—æ•°åŠ èµ·æ¥ï¼Œå¿…é¡»**ä¸¥æ ¼ç­‰äº {total_words}**ã€‚

2. **æ•°æ®ç­–ç•¥ (needs_data åˆ¤å®š)**:
   - **True (éœ€è¦æ•°æ®)**: ç« èŠ‚æ ‡é¢˜åŒ…å«â€œç°çŠ¶â€ã€â€œåˆ†æâ€ã€â€œå®è¯â€ã€â€œç»Ÿè®¡â€ã€â€œè°ƒç ”â€ã€â€œåº”ç”¨â€ã€â€œå¯¹æ¯”â€ã€â€œå®éªŒâ€ã€â€œç»“æœâ€ç­‰è¯æ±‡ï¼Œæˆ–æ¶‰åŠå…·ä½“è¡Œä¸šèƒŒæ™¯æè¿°ã€‚
   - **False (çº¯ç†è®º)**: ç« èŠ‚æ ‡é¢˜ä¸ºâ€œç»ªè®ºâ€ã€â€œå®šä¹‰â€ã€â€œæ¦‚å¿µâ€ã€â€œç†è®ºåŸºç¡€â€ã€â€œç ”ç©¶æ–¹æ³•â€ã€â€œæ–‡çŒ®ç»¼è¿°â€ã€â€œç»“è®ºâ€ã€â€œè‡´è°¢â€ã€‚

# å¾…è§„åˆ’å¤§çº²
{outline_text}

# è¾“å‡ºæ ¼å¼ (JSON Only)
è¯·ç›´æ¥è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ã€‚
Key æ˜¯ç« èŠ‚çš„**å®Œæ•´æ ‡é¢˜**ã€‚
Value æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼ŒåŒ…å« `words` (æ•´æ•°) å’Œ `needs_data` (å¸ƒå°”å€¼)ã€‚

**ä¸¥ç¦**åŒ…å« Markdown æ ‡è®°ï¼Œ**ä¸¥ç¦**åºŸè¯ã€‚

ç¤ºä¾‹æ ¼å¼ï¼š
{{
    "1.1 ç ”ç©¶èƒŒæ™¯": {{ "words": 400, "needs_data": true }},
    "1.2 æ ¸å¿ƒæ¦‚å¿µç•Œå®š": {{ "words": 300, "needs_data": false }},
    "3.1 å¸‚åœºç°çŠ¶åˆ†æ": {{ "words": 800, "needs_data": true }}
}}
"""

class PaperAutoWriter:
    def __init__(self, api_key: str, base_url: str, model: str):
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        # ä¸»çº¿ç¨‹å®¢æˆ·ç«¯
        self.main_client = OpenAI(api_key=api_key, base_url=base_url, timeout=120.0)

    # --------------------------------------------------------------------------
    # è¾…åŠ©æ–¹æ³•ï¼šClient éš”ç¦»è°ƒç”¨
    # --------------------------------------------------------------------------
    
    def _call_llm_with_client(self, client, system_prompt: str, user_prompt: str) -> str:
        """[åŸºç¡€æ–¹æ³•] ä½¿ç”¨æŒ‡å®šçš„ client å®ä¾‹è°ƒç”¨ LLM"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
                    temperature=0.7, 
                    stream=False
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                print(f"âš ï¸ [LLM Error] Attempt {attempt+1}/{max_retries}: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    raise e # æŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚æ•è·

    def _call_llm(self, system_prompt: str, user_prompt: str) -> str:
        """[ä¸»çº¿ç¨‹] è°ƒç”¨æ–¹æ³•"""
        return self._call_llm_with_client(self.main_client, system_prompt, user_prompt)

    # --------------------------------------------------------------------------
    # è”ç½‘æœç´¢æ–¹æ³•
    # --------------------------------------------------------------------------
    
    def _research_phase_with_client(self, client, topic: str) -> str:
        try:
            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä¸¥è°¨æ•°æ®åˆ†æå¸ˆã€‚åˆ—å‡ºå…³äºä¸»é¢˜çš„çœŸå®æ•°æ®ã€æ”¿ç­–ã€‚"},
                    {"role": "user", "content": f"æ£€ç´¢å…³äº'{topic}'çš„çœŸå®äº‹å®ï¼š"}
                ],
                temperature=0.3, stream=False
            )
            return response.choices[0].message.content.strip()
        except: 
            return ""

    def _research_phase(self, topic: str) -> str:
        return self._research_phase_with_client(self.main_client, topic)

    # --------------------------------------------------------------------------
    # çŠ¶æ€æ£€æŸ¥
    # --------------------------------------------------------------------------

    def _check_process_status(self, check_status_func) -> bool:
        while check_status_func() == "paused":
            time.sleep(1)
        return check_status_func() == "stopped"

    def _extract_chapter_num(self, title: str) -> str:
        match = re.match(r'^(\d+)', title.strip())
        return match.group(1) if match else ""

    def _determine_header_prefix(self, chapter: Dict, sec_title: str) -> str:
        level = 2
        if 'level' in chapter: level = int(chapter['level']) + 1
        return "#" * min(max(level, 2), 6)

    def _clean_and_format(self, raw_content: str, sec_title: str, ref_manager) -> str:
        if "æ‘˜è¦" in sec_title or "Abstract" in sec_title:
            raw_content = re.sub(r'^#+\s*(æ‘˜è¦|Abstract)\s*', '', raw_content, flags=re.IGNORECASE).strip()
        
        dirty_patterns = [r'[\(ï¼ˆ]æ¥ä¸Šæ–‡[\)ï¼‰]', r'[\(ï¼ˆ]ç©ºä¸¤æ ¼[\)ï¼‰]', r'^\.\.\.', r'æ¥ä¸Šæ–‡ï¼š']
        for p in dirty_patterns:
            raw_content = re.sub(p, '', raw_content)

        if ref_manager:
            raw_content = ref_manager.process_text_deterministic(raw_content)
        
        processed = TextCleaner.convert_cn_numbers(raw_content)
        lines = []
        for line in processed.split('\n'):
            line = line.strip()
            if (line and not line.startswith('ã€€ã€€') and not line.startswith('#') and 
                not line.startswith('|') and not line.startswith('```') and "import" not in line):
                line = 'ã€€ã€€' + line 
            lines.append(line)
        return '\n\n'.join(lines)

    def _refine_content(self, raw_content: str, target: int, sec_title: str, sys_prompt: str, user_prompt: str) -> Generator[str, None, str]:
        content_no_code = re.sub(r'```[\s\S]*?```', '', raw_content)
        current_len = len(re.sub(r'\s', '', content_no_code))
        if target < 300: return raw_content
        
        # ç®€åŒ–ç‰ˆç²¾ç®€é€»è¾‘ï¼Œé˜²æ­¢é€’å½’æŠ¥é”™
        return raw_content

    # --------------------------------------------------------------------------
    # [æ ¸å¿ƒä¿®å¤] å•ç« èŠ‚å¤„ç†å‡½æ•° (å¢åŠ è¯¦ç»†Debug Log)
    # --------------------------------------------------------------------------
    
    def _process_single_chapter(self, task_bundle):
        """çº¿ç¨‹å·¥ä½œå‡½æ•°"""
        i = -1
        sec_title = "æœªçŸ¥ç« èŠ‚"
        logs = []
        
        try:
            if len(task_bundle) < 12: 
                return { "index": -1, "type": "error", "msg": f"å‚æ•°ä¸è¶³: {len(task_bundle)}", "logs": [] }

            (api_key, base_url, model, task_id, title, chapter, 
             ref_domestic, ref_foreign,  # <--- è¿™é‡Œæ¥æ”¶åˆ†å¼€çš„æ–‡çŒ®
             custom_data, context_summary, index_val, 
             full_outline_str) = task_bundle
            
            i = index_val
            sec_title = chapter.get('title', 'æ— æ ‡é¢˜')
            target = int(chapter.get('words', 500))
            is_parent = chapter.get('is_parent', False)

            # Debug Print
            # print(f"[Thread {i}] å¤„ç†ç« èŠ‚: {sec_title} | å­—æ•°: {target}")

            # 2. æ ‡é¢˜å¤„ç† (çˆ¶èŠ‚ç‚¹ç›´æ¥è¿”å›)
            header_prefix = self._determine_header_prefix(chapter, sec_title)
            if is_parent or target <= 0:
                return {
                    "index": i, "type": "header_only", 
                    "content": f"{header_prefix} {sec_title}\n\n",
                    "logs": [f"ç”Ÿæˆæ ‡é¢˜: {sec_title}"]
                }

            # 3. åˆå§‹åŒ– Client
            local_client = OpenAI(api_key=api_key, base_url=base_url, timeout=120.0)
            
            chapter_num = self._extract_chapter_num(sec_title)
            logs.append(f"ğŸš€ [å¹¶å‘å¯åŠ¨] æ­£åœ¨æ’°å†™: {sec_title}")

            # 4. æ•°æ®ä¸Šä¸‹æ–‡å‡†å¤‡
            facts_context = ""
            use_data_flag = chapter.get('use_data', False)
            has_user_data = False
            
            if "æ‘˜è¦" not in sec_title and use_data_flag:
                if custom_data and len(custom_data.strip()) > 5:
                    cleaned_data = TextCleaner.convert_cn_numbers(custom_data)
                    facts_context += f"\nã€ç”¨æˆ·çœŸå®æ•°æ®ã€‘:\n{cleaned_data}\n"
                    has_user_data = True
                
                # logs.append(f"   - ğŸ” [å¹¶è¡Œæ£€ç´¢] è¡¥å……æ•°æ®...")
                facts = self._research_phase_with_client(local_client, f"{title} - {sec_title} æ•°æ®")
                if facts:
                    facts_context += f"\nã€è”ç½‘è¡¥å……æ•°æ®ã€‘:\n{facts}\n"

            # [ä¿®æ”¹] 5. æ™ºèƒ½æ–‡çŒ®é€‰æ‹©é€»è¾‘
            target_ref_list = []
            
            # åˆ¤æ–­é€»è¾‘ï¼šæ ¹æ®æ ‡é¢˜å…³é”®è¯é”å®šæ–‡çŒ®åº“
            is_domestic_review = "å›½å†…" in sec_title and ("ç°çŠ¶" in sec_title or "ç»¼è¿°" in sec_title)
            is_foreign_review = "å›½å¤–" in sec_title and ("ç°çŠ¶" in sec_title or "ç»¼è¿°" in sec_title)
            
            raw_ref_text = ""

            if is_domestic_review:
                logs.append(f"   - ğŸ“š é”å®šï¼šå›½å†…å‚è€ƒæ–‡çŒ®")
                raw_ref_text = ref_domestic
            elif is_foreign_review:
                logs.append(f"   - ğŸ“š é”å®šï¼šå›½å¤–å‚è€ƒæ–‡çŒ®")
                raw_ref_text = ref_foreign
            else:
                # å…¶ä»–ç« èŠ‚ï¼ˆå¦‚ç†è®ºã€æ­£æ–‡ï¼‰ï¼Œä¸ºäº†å¼•ç”¨ä¸°å¯Œåº¦ï¼Œåˆå¹¶ä¸¤è€…
                # ä¸­é—´åŠ æ¢è¡Œç¬¦é˜²æ­¢ç²˜è¿
                raw_ref_text = f"{ref_domestic}\n{ref_foreign}"

            # è§£æä¸ºåˆ—è¡¨ (å–å‰8æ¡ï¼Œé˜²æ­¢ Token çˆ†ç‚¸)
            if raw_ref_text:
                target_ref_list = [line.strip() for line in raw_ref_text.split('\n') if line.strip()][:8]

            # 6. Prompt æ„å»º
            sys_prompt = get_academic_thesis_prompt(
                target, 
                target_ref_list, # ä¼ å…¥ç­›é€‰åçš„åˆ—è¡¨
                sec_title, 
                chapter_num, 
                has_user_data, 
                full_outline=full_outline_str
            )
            user_prompt = f"é¢˜ç›®ï¼š{title}\nç« èŠ‚ï¼š{sec_title}\nå‰æ–‡æ‘˜è¦ï¼š{context_summary}\nã€é‡è¦çº¦æŸã€‘ç›®æ ‡å­—æ•°ï¼š{target}å­—\n{facts_context}"

            # 7. LLM è°ƒç”¨
            raw_content = self._call_llm_with_client(local_client, sys_prompt, user_prompt)

            # 8. ç®€å•å­—æ•°æ£€æŸ¥ä¸æ‰©å†™ (çœç•¥è¯¦ç»†é€»è¾‘ï¼Œä¿æŒåŸæœ‰å³å¯)
            content_no_code = re.sub(r'```[\s\S]*?```', '', raw_content)
            current_len = len(re.sub(r'\s', '', content_no_code))
            if "æ‘˜è¦" not in sec_title and target > 300 and current_len < target * 0.5:
                 try:
                    raw_content = self._call_llm_with_client(local_client, sys_prompt, user_prompt + "\n\nè¯·å¤§å¹…æ‰©å†™ï¼Œå¢åŠ ç»†èŠ‚ã€‚")
                 except: pass

            # 9. æ¸…æ´—
            # è¿™é‡Œçš„ ref_manager ä¼  None å³å¯ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ Prompt é‡Œå·²ç»å¤„ç†äº†å¼•ç”¨æ ¼å¼
            final_content = self._clean_and_format(raw_content, sec_title, None)
            section_md = f"{header_prefix} {sec_title}\n\n{final_content}\n\n"
            
            return {
                "index": i, "type": "content", 
                "content": section_md, "raw_text": final_content, "logs": logs
            }

        except Exception as e:
            err_msg = f"âŒ {sec_title} å¼‚å¸¸: {str(e)}"
            print(f"[Thread {i}] ERROR: {err_msg}")
            return { "index": i, "type": "error", "msg": str(e), "logs": [err_msg] }

    # --------------------------------------------------------------------------
    # å¹¶å‘ç”Ÿæˆå™¨
    # --------------------------------------------------------------------------
    def _format_outline(self, chapters: List[Dict]) -> str:
        outline_lines = []
        for ch in chapters:
            title = ch.get('title', 'æœªå‘½å')
            outline_lines.append(f"- {title}")
        return "\n".join(outline_lines)

    def generate_stream(self, task_id: str, title: str, chapters: List[Dict], ref_domestic: str, ref_foreign: str, custom_data: str, check_status_func, initial_context: str = "") -> Generator[str, None, None]:
        
        # è¿™é‡Œçš„ ref_manager ä¸»è¦ç”¨äºæœ€åç”Ÿæˆæ–‡æœ«çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼Œæ‰€ä»¥åˆå¹¶ä¸¤è€…
        combined_refs = f"{ref_domestic}\n{ref_foreign}"
        ref_manager = ReferenceManager(combined_refs)
        
        yield f"data: {json.dumps({'type': 'log', 'msg': 'ğŸš€ å¯åŠ¨é«˜å¹¶å‘ç”Ÿæˆå¼•æ“ (Max Threads=8)...'})}\n\n"
        
        full_content = f"# {title}\n\n"
        global_context = initial_context if initial_context else f"è®ºæ–‡é¢˜ç›®ï¼šã€Š{title}ã€‹"
        
        # é¢„å…ˆç”Ÿæˆå…¨æ–‡å¤§çº²æ–‡æœ¬å­—ç¬¦ä¸²
        full_outline_str = self._format_outline(chapters)

        MAX_WORKERS = 8
        all_futures = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # 1. æäº¤ä»»åŠ¡
            for i, chapter in enumerate(chapters):
                if self._check_process_status(check_status_func): break
                
                task_bundle = (
                    self.api_key, self.base_url, self.model,
                    task_id, title, chapter, 
                    ref_domestic, ref_foreign,  # <--- æ–°å¢çš„ä¸¤ä¸ªå‚æ•°
                    custom_data, global_context[:800], i,
                    full_outline_str
                )
                future = executor.submit(self._process_single_chapter, task_bundle)
                all_futures.append(future)
            
            # 2. è·å–ç»“æœ
            for future in all_futures:
                if self._check_process_status(check_status_func):
                    executor.shutdown(wait=False)
                    break
                
                while True:
                    try:
                        result = future.result(timeout=1)
                        for log in result.get('logs', []):
                            yield f"data: {json.dumps({'type': 'log', 'msg': log})}\n\n"
                        
                        if result['type'] == 'error':
                            yield f"data: {json.dumps({'type': 'log', 'msg': result['msg']})}\n\n"
                            break

                        if result['type'] in ['content', 'header_only']:
                            content_md = result['content']
                            full_content += content_md
                            yield f"data: {json.dumps({'type': 'content', 'md': content_md})}\n\n"
                            global_context += result.get('raw_text', '')[-200:]
                        
                        break
                    except concurrent.futures.TimeoutError:
                        yield f": keep-alive\n\n"
                        if self._check_process_status(check_status_func): return
                    except Exception as e:
                        yield f"data: {json.dumps({'type': 'log', 'msg': f'âŒ ä¸»çº¿ç¨‹å¼‚å¸¸: {str(e)}'})}\n\n"
                        break

        if check_status_func() != "stopped":
            # ç”Ÿæˆæ–‡æœ«å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            bib = ref_manager.generate_bibliography()
            full_content += bib
            yield f"data: {json.dumps({'type': 'content', 'md': bib})}\n\n"
            yield f"data: {json.dumps({'type': 'done'})}\n\n"

    # --------------------------------------------------------------------------
    # å…¶ä»–å…¬å…±æ–¹æ³•
    # --------------------------------------------------------------------------

    def rewrite_chapter(self, title: str, section_title: str, user_instruction: str, context: str, custom_data: str, original_content: str = "") -> str:
        sys_prompt = get_rewrite_prompt(title, section_title, user_instruction, context[-800:], custom_data, original_content)
        user_prompt = f"è®ºæ–‡é¢˜ç›®ï¼š{title}\nè¯·ä¿®æ”¹ç« èŠ‚ï¼š{section_title}\nç”¨æˆ·çš„å…·ä½“ä¿®æ”¹æ„è§ï¼š{user_instruction}"
        return self._call_llm(sys_prompt, user_prompt)
    
    def plan_word_count(self, total_words: int, outline_list: List[str]) -> Dict[str, Dict]:
        outline_str = "\n".join(outline_list)
        prompt = get_word_distribution_prompt(total_words, outline_str)
        
        try:
            response = self.main_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼è¾“å‡º JSON çš„å­¦æœ¯è§„åˆ’å¸ˆã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                stream=False,
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content.strip()
            if content.startswith("```"): content = re.sub(r'```json|```', '', content).strip()
            
            try:
                raw_map = json.loads(content)
            except json.JSONDecodeError:
                return {}

            standardized_map = {}
            for k, v in raw_map.items():
                if "total" in k.lower(): continue
                if isinstance(v, dict):
                    w = int(v.get('words', 0))
                    d = v.get('needs_data', False)
                    if isinstance(d, str): d = d.lower() == 'true'
                    standardized_map[k] = {"words": w, "needs_data": d}
                elif isinstance(v, (int, float)):
                    standardized_map[k] = {"words": int(v), "needs_data": False}
            
            current_total = sum(item['words'] for item in standardized_map.values())
            if current_total == 0: return standardized_map

            ratio = total_words / current_total
            final_map = {}
            for k, v in standardized_map.items():
                final_map[k] = {"words": int(v['words'] * ratio), "needs_data": v['needs_data']}
            
            # è¯¯å·®ä¿®æ­£
            new_total = sum(item['words'] for item in final_map.values())
            diff = total_words - new_total
            if diff != 0 and final_map:
                max_key = max(final_map, key=lambda k: final_map[k]['words'])
                final_map[max_key]['words'] += diff
                
            return final_map
        except Exception as e:
            print(f"Plan error: {e}")
            return {}