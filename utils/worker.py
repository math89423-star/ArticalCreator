# utils/worker.py
import time
import json
from utils.state import task_manager
from utils.files import extract_file_content

def background_worker(
        writer, 
        task_id, 
        title, 
        chapters, 
        ref_domestic, 
        ref_foreign, 
        text_custom_data, 
        raw_files_data, 
        check_status_func, 
        initial_context, 
        user_id, 
        extra_instructions):
    try:
        # 1. åœ¨åå°çº¿ç¨‹ä¸­è¿›è¡Œæ–‡ä»¶è§£æ
        final_custom_data = text_custom_data
        
        if raw_files_data:
            task_manager.append_event(user_id, task_id, f"data: {json.dumps({'type': 'log', 'msg': 'ğŸ“‚ æ­£åœ¨åå°è§£æä¸Šä¼ çš„æ–‡ä»¶ (å«å›¾ç‰‡è¯†åˆ«)...'})}\n\n")
            
            file_extracted_text = ""
            for file_info in raw_files_data:
                time.sleep(0.01) # é‡Šæ”¾ GIL
                
                try:
                    # [ä¿®æ”¹] ä¼ å…¥ writer.main_client ä»¥æ”¯æŒå›¾ç‰‡è§£æ
                    extracted = extract_file_content(
                        file_info['content'], 
                        file_info['name'], 
                        llm_client=writer.main_client
                    )
                    file_extracted_text += extracted + "\n\n"

                    # 1. æœåŠ¡å™¨åå°æ‰“å° (å®Œæ•´å†…å®¹ï¼Œç”¨äºæ·±åº¦æ’æŸ¥)
                    print(f"\n{'='*30} [DEBUG] è§£ææ–‡ä»¶: {file_info['name']} {'='*30}")
                    print(f"è§£æé•¿åº¦: {len(file_extracted_text)} å­—ç¬¦")
                    print(f"è§£æå†…å®¹:\n{file_extracted_text}")  # è¿™é‡Œä¼šæ‰“å°å…¨éƒ¨è§£æå‡ºçš„æ–‡å­—/å›¾ç‰‡æè¿°
                    print(f"{'='*80}\n")

                    # 2. å‰ç«¯ç•Œé¢æ—¥å¿— (é¢„è§ˆå†…å®¹ï¼Œç”¨äºå¿«é€Ÿç¡®è®¤)
                    # å»æ‰å¤šä½™æ¢è¡Œï¼Œæˆªå–å‰ 300 å­—é¢„è§ˆ
                    preview = file_extracted_text.replace('\n', ' ').strip()[:300]
                    debug_msg = f"ğŸ” [è§£æç»“æœ] {file_info['name']} (len={len(file_extracted_text)}):\n{preview}..."
                    task_manager.append_event(user_id, task_id, f"data: {json.dumps({'type': 'log', 'msg': debug_msg})}\n\n")


                    # å¦‚æœæ˜¯å›¾ç‰‡ï¼Œè®°å½•ä¸€æ¡ç‰¹æ®Šçš„æ—¥å¿—
                    if file_info['name'].lower().endswith(('.png', '.jpg', '.jpeg')):
                        img_msg = f"ğŸ‘ï¸ å›¾ç‰‡è¯†åˆ«å®Œæˆ: {file_info['name']}"
                        json_payload = json.dumps({'type': 'log', 'msg': img_msg})
                        task_manager.append_event(user_id, task_id, f"data: {json_payload}\n\n")

                except Exception as e:
                    file_extracted_text += f"\næ–‡ä»¶ {file_info['name']} è§£æå¤±è´¥: {e}\n"
            
            final_custom_data = text_custom_data + "\n" + file_extracted_text
        
        if raw_files_data:
            task_manager.append_event(user_id, task_id, f"data: {json.dumps({'type': 'log', 'msg': 'ğŸ“‚ æ­£åœ¨åå°è§£æä¸Šä¼ çš„æ–‡ä»¶...'})}\n\n")
            
            file_extracted_text = ""
            for file_info in raw_files_data:
                time.sleep(0.01) # é‡Šæ”¾ GIL
                
                try:
                    extracted = extract_file_content(file_info['content'], file_info['name'])
                    file_extracted_text += extracted + "\n\n"
                except Exception as e:
                    file_extracted_text += f"\næ–‡ä»¶ {file_info['name']} è§£æå¤±è´¥: {e}\n"
            
            final_custom_data = text_custom_data + "\n" + file_extracted_text
            task_manager.append_event(user_id, task_id, f"data: {json.dumps({'type': 'log', 'msg': 'âœ… æ–‡ä»¶è§£æå®Œæˆï¼Œå¼€å§‹ç”Ÿæˆ...'})}\n\n")

        # 2. æ‰§è¡Œç”Ÿæˆå™¨
        generator = writer.generate_stream(
            task_id, title, chapters, ref_domestic, ref_foreign, final_custom_data, check_status_func, initial_context, extra_instructions
        )
        
        # 3. é€æ¡æ¶ˆè´¹
        for chunk in generator:
            if check_status_func() == 'stopped':
                print(f"[Worker] çº¿ç¨‹æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º: {task_id}")
                return
            task_manager.append_event(user_id, task_id, chunk)
            time.sleep(0.005) 
            
    except Exception as e:
        error_msg = json.dumps({'type': 'log', 'msg': f'âŒ åå°ä»»åŠ¡å¼‚å¸¸: {str(e)}'})
        task_manager.append_event(user_id, task_id, f"data: {error_msg}\n\n")
    finally:
        current_status = task_manager.get_status(user_id, task_id)
        if current_status == 'running':
            task_manager.set_status(user_id, task_id, 'completed')