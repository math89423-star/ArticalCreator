
import re
import json
import time
import base64
import concurrent.futures
from openai import OpenAI
from typing import Dict, List, Generator, Optional
from .reference import ReferenceManager
from .word import TextCleaner
from .prompts import get_rewrite_prompt, get_word_distribution_prompt, get_academic_thesis_prompt
from .word import MarkdownToDocx


class PaperAutoWriter:
    def __init__(self, api_key: str, base_url: str, model: str):
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        # ä¸»çº¿ç¨‹å®¢æˆ·ç«¯
        self.main_client = OpenAI(api_key=api_key, base_url=base_url, timeout=120.0)
    
    def _call_llm_with_client(self, client, system_prompt: str, user_prompt: str) -> str:
        """[åŸºç¡€æ–¹æ³•] ä½¿ç”¨æŒ‡å®šçš„ client å®ä¾‹è°ƒç”¨ LLM"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
                    temperature=0.7, 
                    stream=False
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                print(f"âš ï¸ [LLM Error] Attempt {attempt+1}/{max_retries}: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    raise e 

    def _call_llm(self, system_prompt: str, user_prompt: str) -> str:
        """[ä¸»çº¿ç¨‹] è°ƒç”¨æ–¹æ³•"""
        return self._call_llm_with_client(self.main_client, system_prompt, user_prompt)

    def _research_phase_with_client(self, client, topic: str) -> str:
        try:
            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä¸¥è°¨æ•°æ®åˆ†æå¸ˆã€‚åˆ—å‡ºå…³äºä¸»é¢˜çš„çœŸå®æ•°æ®ã€æ”¿ç­–ã€‚"},
                    {"role": "user", "content": f"æ£€ç´¢å…³äº'{topic}'çš„çœŸå®äº‹å®ï¼š"}
                ],
                temperature=0.3, stream=False
            )
            return response.choices[0].message.content.strip()
        except: 
            return ""

    def _research_phase(self, topic: str) -> str:
        return self._research_phase_with_client(self.main_client, topic)

    def _check_process_status(self, check_status_func) -> bool:
        while check_status_func() == "paused":
            time.sleep(1)
        return check_status_func() == "stopped"

    def _extract_chapter_num(self, title: str) -> str:
        match = re.match(r'^(\d+)', title.strip())
        return match.group(1) if match else ""

    def _determine_header_prefix(self, chapter: Dict, sec_title: str) -> str:
        level = 2
        if 'level' in chapter: level = int(chapter['level']) + 1
        return "#" * min(max(level, 2), 6)

    def _clean_and_format(self, raw_content: str, sec_title: str, ref_manager) -> str:
        if "æ‘˜è¦" in sec_title or "Abstract" in sec_title:
            raw_content = re.sub(r'^#+\s*(æ‘˜è¦|Abstract)\s*', '', raw_content, flags=re.IGNORECASE).strip()
        dirty_patterns = [r'[\(ï¼ˆ]æ¥ä¸Šæ–‡[\)ï¼‰]', r'[\(ï¼ˆ]ç©ºä¸¤æ ¼[\)ï¼‰]', r'^\.\.\.', r'æ¥ä¸Šæ–‡ï¼š']
        for p in dirty_patterns:
            raw_content = re.sub(p, '', raw_content)
        if ref_manager:
            raw_content = ref_manager.process_text_deterministic(raw_content)
        processed = TextCleaner.convert_cn_numbers(raw_content)
        lines = []
        for line in processed.split('\n'):
            line = line.strip()
            if (line and not line.startswith('ã€€ã€€') and not line.startswith('#') and 
                not line.startswith('|') and not line.startswith('```') and "import" not in line):
                line = 'ã€€ã€€' + line 
            lines.append(line)
        return '\n\n'.join(lines)

    def _refine_content(self, raw_content: str, target: int, sec_title: str, sys_prompt: str, user_prompt: str) -> Generator[str, None, str]:
        content_no_code = re.sub(r'```[\s\S]*?```', '', raw_content)
        current_len = len(re.sub(r'\s', '', content_no_code))
        if target < 300: return raw_content
        return raw_content

    def _fix_markdown_table_format(self, text):
        """
        [V18.0] å¼ºåŠ›ä¿®å¤è¡¨æ ¼æ ¼å¼
        1. è¯†åˆ«è¡¨æ ¼è¡Œï¼Œå¼ºåˆ¶å»é™¤ç¼©è¿› (é˜²æ­¢è¢«å½“åšä»£ç å—)
        2. ç¡®ä¿è¡¨æ ¼ä¸ä¸Šæ–¹æ–‡æœ¬ä¹‹é—´æœ‰ç©ºè¡Œ (Markdown æ ‡å‡†)
        """
        lines = text.split('\n')
        new_lines = []
        in_table = False
        
        for line in lines:
            # å…¼å®¹å…¨è§’ç©ºæ ¼çš„å»é™¤
            stripped = line.strip().replace('\u3000', '')
            
            # åˆ¤å®šæ˜¯å¦ä¸ºè¡¨æ ¼è¡Œ (ä»¥ | å¼€å¤´å¹¶ç»“å°¾)
            # å®½æ¾åŒ¹é…ï¼šåªè¦å»ç©ºåä»¥ | å¼€å¤´ä¸”åŒ…å«ç¬¬äºŒä¸ª | å³å¯
            is_table_row = stripped.startswith('|') and stripped.count('|') >= 2
            
            if is_table_row:
                if not in_table:
                    # [è¿›å…¥è¡¨æ ¼] 
                    # æ£€æŸ¥ä¸Šä¸€è¡Œæ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸æ˜¯ï¼Œæ’å…¥ç©ºè¡Œ
                    if new_lines and new_lines[-1].strip() != '':
                        new_lines.append('') 
                    in_table = True
                
                # å†™å…¥å»ç¼©è¿›åçš„è¡Œ
                new_lines.append(stripped)
            else:
                if in_table:
                    # [é€€å‡ºè¡¨æ ¼]
                    # æ’å…¥ç©ºè¡Œ
                    if stripped != '':
                        new_lines.append('')
                    in_table = False
                
                # éè¡¨æ ¼è¡Œä¿æŒåŸæ · (ä¿ç•™åŸæœ‰çš„ç¼©è¿›)
                new_lines.append(line)
        return '\n'.join(new_lines)
    
    def _process_single_chapter(self, task_bundle):
        """çº¿ç¨‹å·¥ä½œå‡½æ•° (ä¿®å¤ç‰ˆ)"""
        i = -1
        sec_title = "æœªçŸ¥ç« èŠ‚"
        logs = []
        try:
            if len(task_bundle) < 12: 
                return { "index": -1, "type": "error", "msg": f"å‚æ•°ä¸è¶³: {len(task_bundle)}", "logs": [] }

            (api_key, base_url, model, task_id, title, chapter, 
             ref_domestic, ref_foreign, 
             custom_data, context_summary, index_val, 
             full_outline_str) = task_bundle
            
            i = index_val
            sec_title = chapter.get('title', 'æ— æ ‡é¢˜')
            target = int(chapter.get('words', 500))
            is_parent = chapter.get('is_parent', False)
            chart_type = chapter.get('chart_type', 'none') # [æ–°å¢] è·å–å›¾è¡¨ç±»å‹

            # 2. æ ‡é¢˜å¤„ç† (çˆ¶èŠ‚ç‚¹ç›´æ¥è¿”å›)
            header_prefix = self._determine_header_prefix(chapter, sec_title)
            if is_parent or target <= 0:
                return {
                    "index": i, "type": "header_only", 
                    "content": f"{header_prefix} {sec_title}\n\n",
                    "logs": [f"ç”Ÿæˆæ ‡é¢˜: {sec_title}"]
                }

            # 3. åˆå§‹åŒ– Client
            local_client = OpenAI(api_key=api_key, base_url=base_url, timeout=120.0)
            
            chapter_num = self._extract_chapter_num(sec_title)
            logs.append(f"ğŸš€ [å¹¶å‘å¯åŠ¨] æ­£åœ¨æ’°å†™: {sec_title}")

            # 4. æ•°æ®ä¸Šä¸‹æ–‡å‡†å¤‡
            facts_context = ""
            use_data_flag = chapter.get('use_data', False)
            has_user_data = False
            
            if "æ‘˜è¦" not in sec_title and use_data_flag:
                if custom_data and len(custom_data.strip()) > 5:
                    cleaned_data = TextCleaner.convert_cn_numbers(custom_data)
                    facts_context += f"\nã€ç”¨æˆ·çœŸå®æ•°æ®ã€‘:\n{cleaned_data}\n"
                    has_user_data = True
                
                # logs.append(f"   - ğŸ” [å¹¶è¡Œæ£€ç´¢] è¡¥å……æ•°æ®...")
                facts = self._research_phase_with_client(local_client, f"{title} - {sec_title} æ•°æ®")
                if facts:
                    facts_context += f"\nã€è”ç½‘è¡¥å……æ•°æ®ã€‘:\n{facts}\n"

            # 5. æ™ºèƒ½æ–‡çŒ®é€‰æ‹©é€»è¾‘
            target_ref_list = []
            is_domestic_review = "å›½å†…" in sec_title and ("ç°çŠ¶" in sec_title or "ç»¼è¿°" in sec_title)
            is_foreign_review = "å›½å¤–" in sec_title and ("ç°çŠ¶" in sec_title or "ç»¼è¿°" in sec_title)
            
            raw_ref_text = ""
            if is_domestic_review:
                logs.append(f"   - ğŸ“š é”å®šï¼šå›½å†…å‚è€ƒæ–‡çŒ®")
                raw_ref_text = ref_domestic
            elif is_foreign_review:
                logs.append(f"   - ğŸ“š é”å®šï¼šå›½å¤–å‚è€ƒæ–‡çŒ®")
                raw_ref_text = ref_foreign
            else:
                raw_ref_text = f"{ref_domestic}\n{ref_foreign}"

            if raw_ref_text:
                target_ref_list = [line.strip() for line in raw_ref_text.split('\n') if line.strip()][:8]

            # 6. Prompt æ„å»º
            sys_prompt = get_academic_thesis_prompt(
                target, 
                target_ref_list, 
                sec_title, 
                chapter_num, 
                has_user_data, 
                full_outline=full_outline_str,
                chart_type=chart_type # [æ–°å¢] ä¼ å…¥å›¾è¡¨ç±»å‹
            )
            user_prompt = f"é¢˜ç›®ï¼š{title}\nç« èŠ‚ï¼š{sec_title}\nå‰æ–‡æ‘˜è¦ï¼š{context_summary}\nã€é‡è¦çº¦æŸã€‘ç›®æ ‡å­—æ•°ï¼š{target}å­—\n{facts_context}"

            # 7. LLM è°ƒç”¨ (åˆæ¬¡ç”Ÿæˆ)
            content = self._call_llm_with_client(local_client, sys_prompt, user_prompt)

            # 8. å­—æ•°æ£€æŸ¥ä¸æ‰©å†™
            #    å…ˆå»æ‰ä»£ç å—ç®—å­—æ•°ï¼Œé¿å…è¢«ä»£ç æ’‘å¤§
            content_no_code = re.sub(r'```[\s\S]*?```', '', content)
            current_len = len(re.sub(r'\s', '', content_no_code))
            
            if "æ‘˜è¦" not in sec_title and target > 300 and current_len < target * 0.5:
                 try:
                    logs.append(f"   - âš ï¸ å­—æ•°ä¸è¶³({current_len}/{target})ï¼Œè§¦å‘æ‰©å†™...")
                    # æ‰©å†™ç»“æœç›´æ¥è¦†ç›– content
                    content = self._call_llm_with_client(local_client, sys_prompt, user_prompt + "\n\nè¯·å¤§å¹…æ‰©å†™ï¼Œå¢åŠ ç»†èŠ‚ï¼Œç¡®ä¿å­—æ•°è¾¾æ ‡ã€‚")
                 except Exception as e:
                    print(f"æ‰©å†™å¤±è´¥: {e}")

            # =========================================================
            # [æ–°å¢] åå¤„ç†ï¼šå°† Python ä»£ç å—è½¬æ¢ä¸º Base64 å›¾ç‰‡
            # (æ”¾åœ¨æ‰©å†™ä¹‹åï¼Œç¡®ä¿æ‰©å†™ç”Ÿæˆçš„ä»£ç ä¹Ÿèƒ½è¢«è½¬æ¢)
            # =========================================================
            def replacer(match):
                code = match.group(1)
                img_buf = MarkdownToDocx.exec_python_plot(code)
                if img_buf:
                    b64_data = base64.b64encode(img_buf.getvalue()).decode('utf-8')
                    return f"\n![ç»Ÿè®¡å›¾](data:image/png;base64,{b64_data})\n"
                else:
                    return match.group(0)

            content = re.sub(r'```python\s+(.*?)```', replacer, content, flags=re.DOTALL)
            content = self._clean_and_format(content, sec_title, None)
            final_content = self._fix_markdown_table_format(content)
            section_md = f"{header_prefix} {sec_title}\n\n{final_content}\n\n"

            return {
                "index": i, "type": "content", 
                "content": section_md, "raw_text": final_content, "logs": logs
            }
        except Exception as e:
            err_msg = f"âŒ {sec_title} å¼‚å¸¸: {str(e)}"
            print(f"[Thread {i}] ERROR: {err_msg}")
            return { "index": i, "type": "error", "msg": str(e), "logs": [err_msg] }
        
    def write_section_content(self, 
                              section_title: str, 
                              word_count: int, 
                              references: List[str], 
                              full_outline_str: str,
                              chapter_num: str,
                              has_data: bool = False,
                              opening_report: Optional[Dict] = None) -> Generator[str, None, None]:
        """
        æµå¼ç”Ÿæˆç« èŠ‚å†…å®¹
        :param opening_report: è§£æåçš„å¼€é¢˜æŠ¥å‘Šå­—å…¸ (title, review, outline_content)
        """
        
        # 1. ç­–ç•¥ A: ç›´æ¥å†…å®¹å¤ç”¨ (Direct Hit)
        # å¦‚æœå½“å‰ç« èŠ‚æ˜¯â€œæ–‡çŒ®ç»¼è¿°â€ä¸”å¼€é¢˜æŠ¥å‘Šé‡Œæœ‰å¤§æ®µç»¼è¿°ï¼Œå¯ä»¥è€ƒè™‘ç›´æ¥è¿”å›
        # ä½†ä¸ºäº†ä¿æŒæ–‡é£ç»Ÿä¸€ï¼Œè¿™é‡Œé€‰æ‹©å°†å¼€é¢˜æŠ¥å‘Šä½œä¸º Context ä¼ å…¥ Prompt (Strategy I)ï¼Œ
        # è®© LLM è¿›è¡Œæ¶¦è‰²å’Œæ‰©å†™ï¼Œè€Œä¸æ˜¯ç”Ÿç¡¬çš„ Copy-Pasteã€‚
        
        # 2. æ„å»ºç³»ç»Ÿæç¤ºè¯ (åŒ…å«å¼€é¢˜æŠ¥å‘Šçº¦æŸ)
        system_prompt = get_academic_thesis_prompt(
            target_words=word_count,
            ref_content_list=references,
            current_chapter_title=section_title,
            chapter_num=chapter_num,
            has_user_data=has_data,
            full_outline=full_outline_str,
            opening_report_data=opening_report # <--- ä¼ å…¥å¼€é¢˜æŠ¥å‘Šæ•°æ®
        )

        user_prompt = f"è¯·æ’°å†™ç« èŠ‚ï¼šã€{section_title}ã€‘\nè¦æ±‚å­—æ•°ï¼šçº¦ {word_count} å­—ã€‚"
        
        # 3. æµå¼è°ƒç”¨
        for chunk in self._call_llm_stream_with_client(self.main_client, system_prompt, user_prompt):
            yield chunk

    # --------------------------------------------------------------------------
    # å¹¶å‘ç”Ÿæˆå™¨
    # --------------------------------------------------------------------------
    def _format_outline(self, chapters: List[Dict]) -> str:
        outline_lines = []
        for ch in chapters:
            title = ch.get('title', 'æœªå‘½å')
            outline_lines.append(f"- {title}")
        return "\n".join(outline_lines)

    def generate_stream(self, task_id: str, title: str, chapters: List[Dict], ref_domestic: str, ref_foreign: str, custom_data: str, check_status_func, initial_context: str = "") -> Generator[str, None, None]:
        
        # è¿™é‡Œçš„ ref_manager ä¸»è¦ç”¨äºæœ€åç”Ÿæˆæ–‡æœ«çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼Œæ‰€ä»¥åˆå¹¶ä¸¤è€…
        combined_refs = f"{ref_domestic}\n{ref_foreign}"
        ref_manager = ReferenceManager(combined_refs)
        yield f"data: {json.dumps({'type': 'log', 'msg': 'ğŸš€ å¯åŠ¨é«˜å¹¶å‘ç”Ÿæˆå¼•æ“ (Max Threads=8)...'})}\n\n"
        full_content = f"# {title}\n\n"
        global_context = initial_context if initial_context else f"è®ºæ–‡é¢˜ç›®ï¼šã€Š{title}ã€‹"
        
        # é¢„å…ˆç”Ÿæˆå…¨æ–‡å¤§çº²æ–‡æœ¬å­—ç¬¦ä¸²
        full_outline_str = self._format_outline(chapters)

        MAX_WORKERS = 8
        all_futures = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # 1. æäº¤ä»»åŠ¡
            for i, chapter in enumerate(chapters):
                if self._check_process_status(check_status_func): break
                
                task_bundle = (
                    self.api_key, self.base_url, self.model,
                    task_id, title, chapter, 
                    ref_domestic, ref_foreign,  # <--- æ–°å¢çš„ä¸¤ä¸ªå‚æ•°
                    custom_data, global_context[:800], i,
                    full_outline_str
                )
                future = executor.submit(self._process_single_chapter, task_bundle)
                all_futures.append(future)
            
            # 2. è·å–ç»“æœ
            for future in all_futures:
                if self._check_process_status(check_status_func):
                    executor.shutdown(wait=False)
                    break
                
                while True:
                    try:
                        result = future.result(timeout=1)
                        for log in result.get('logs', []):
                            yield f"data: {json.dumps({'type': 'log', 'msg': log})}\n\n"
                        
                        if result['type'] == 'error':
                            yield f"data: {json.dumps({'type': 'log', 'msg': result['msg']})}\n\n"
                            break

                        if result['type'] in ['content', 'header_only']:
                            content_md = result['content']
                            full_content += content_md
                            yield f"data: {json.dumps({'type': 'content', 'md': content_md})}\n\n"
                            global_context += result.get('raw_text', '')[-200:]
                        
                        break
                    except concurrent.futures.TimeoutError:
                        yield f": keep-alive\n\n"
                        if self._check_process_status(check_status_func): return
                    except Exception as e:
                        yield f"data: {json.dumps({'type': 'log', 'msg': f'âŒ ä¸»çº¿ç¨‹å¼‚å¸¸: {str(e)}'})}\n\n"
                        break

        if check_status_func() != "stopped":
            # ç”Ÿæˆæ–‡æœ«å‚è€ƒæ–‡çŒ®åˆ—è¡¨
            bib = ref_manager.generate_bibliography()
            full_content += bib
            yield f"data: {json.dumps({'type': 'content', 'md': bib})}\n\n"
            yield f"data: {json.dumps({'type': 'done'})}\n\n"

    # --------------------------------------------------------------------------
    # å…¶ä»–å…¬å…±æ–¹æ³•
    # --------------------------------------------------------------------------

    def rewrite_chapter(self, title: str, section_title: str, user_instruction: str, context: str, custom_data: str, original_content: str = "") -> str:
        chapter_num = self._extract_chapter_num(section_title)
        
        sys_prompt = get_rewrite_prompt(title, section_title, user_instruction, context[-800:], custom_data, original_content, chapter_num)
        
        user_prompt = f"è®ºæ–‡é¢˜ç›®ï¼š{title}\nè¯·ä¿®æ”¹ç« èŠ‚ï¼š{section_title}\nç”¨æˆ·çš„å…·ä½“ä¿®æ”¹æ„è§ï¼š{user_instruction}\nã€æœ€é«˜æŒ‡ä»¤ã€‘ç›´æ¥è¾“å‡ºæ­£æ–‡ã€‚å¦‚æœéœ€è¦ç»˜å›¾ï¼Œè¯·è¾“å‡ºå®Œæ•´çš„ Markdown ä»£ç å— (```python ... ```)ï¼Œä¸è¦è§£é‡Šä»£ç ã€‚"
        
        content = self._call_llm(sys_prompt, user_prompt)

        # =========================================================
        # [Step 1] æ¸…æ´—åºŸè¯æ ‡é¢˜ (ä¿æŒä¸å˜ï¼Œä½†æ›´å°å¿ƒ)
        # =========================================================
        garbage_patterns = [
            r'^\s*(?:#+|\*\*|)?\s*(?:è®¾ç½®|å®šä¹‰|åˆ›å»º|ç»˜åˆ¶|æ·»åŠ |å¯¼å…¥|å‡†å¤‡)(?:ç»˜å›¾)?(?:é£æ ¼|æ•°æ®|å˜é‡|ç”»å¸ƒ|æ¡å½¢å›¾|æŠ˜çº¿å›¾|é¥¼å›¾|ç»Ÿè®¡å›¾|å›¾è¡¨|æ•°å€¼|æ ‡ç­¾|å¼•ç”¨|ç›¸å…³åº“|ä»£ç ).*?$',
            r'^\s*(?:#+|\*\*|)?\s*Python\s*ä»£ç (?:å¦‚ä¸‹|ç¤ºä¾‹)?[:ï¼š]?\s*$',
            r'^\s*(?:#+|\*\*|)?\s*ä»£ç å¦‚ä¸‹[:ï¼š]?\s*$'
        ]
        for pat in garbage_patterns:
            content = re.sub(pat, '', content, flags=re.MULTILINE | re.IGNORECASE)

        # =========================================================
        # [Step 2] æ ¸å¿ƒä¿®å¤ï¼šæ›´å¥å£®çš„ä»£ç å—æå–ä¸æ›¿æ¢
        # =========================================================
        
        # å®šä¹‰ä¸€ä¸ªä¸“é—¨ç”¨æ¥æ‰¾ python ä»£ç å—çš„æ­£åˆ™
        # (```python\s+[\s\S]*?```) : åŒ¹é…å®Œæ•´çš„ä»£ç å—
        code_block_pattern = re.compile(r'(```python\s+[\s\S]*?```)', re.IGNORECASE)
        
        def image_replacer(match):
            full_block = match.group(1) # å®Œæ•´çš„ ```python ... ``` å­—ç¬¦ä¸²
            
            # æå–å†…éƒ¨ä»£ç ï¼šå»æ‰é¦–å°¾çš„ ```python å’Œ ```
            # ä½¿ç”¨ split è€Œä¸æ˜¯æ­£åˆ™ï¼Œé˜²æ­¢è¯¯ä¼¤å†…éƒ¨å†…å®¹
            lines = full_block.strip().split('\n')
            if len(lines) < 2: return "" # ç©ºå—
            
            # å»æ‰ç¬¬ä¸€è¡Œ (```python) å’Œæœ€åä¸€è¡Œ (```)
            code_lines = lines[1:-1]
            code = '\n'.join(code_lines).strip()
            
            if not code: return ""

            try:
                img_buf = MarkdownToDocx.exec_python_plot(code)
                if img_buf:
                    b64_data = base64.b64encode(img_buf.getvalue()).decode('utf-8')
                    # è¿”å›å›¾ç‰‡ HTML
                    return f'\n\n<div align="center" class="plot-container"><img src="data:image/png;base64,{b64_data}" style="max-width:85%; border:1px solid #eee; padding:5px; border-radius:4px;"></div>\n\n'
                else:
                    # å¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œæˆ‘ä»¬é€‰æ‹©ã€ä¿ç•™åŸä»£ç å—ã€‘ï¼Œæ–¹ä¾¿è°ƒè¯•ï¼Œ
                    # æˆ–è€…è¿”å›ç©ºå­—ç¬¦ä¸²éšè—é”™è¯¯ã€‚è¿™é‡Œé€‰æ‹©è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œé¿å…ä¹±ç ã€‚
                    return "" 
            except Exception as e:
                print(f"Plot Logic Error: {e}")
                return ""

        # æ‰§è¡Œæ›¿æ¢
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ re.subï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç†æ‰€æœ‰åŒ¹é…åˆ°çš„å—
        new_content = code_block_pattern.sub(image_replacer, content)
        
        # [Step 3] å…œåº•æ£€æŸ¥ï¼šå¦‚æœæ›¿æ¢åè¿˜æœ‰æ®‹ç•™çš„ ```ï¼Œè¯´æ˜æ ¼å¼åäº†
        # æˆ‘ä»¬å¯ä»¥å°è¯•å¼ºè¡Œç§»é™¤æ‰€æœ‰æ®‹ç•™çš„ ```python å’Œ ```
        # ä½†é€šå¸¸ Step 2 å¤„ç†å®Œåï¼Œnew_content é‡Œåº”è¯¥å·²ç»æ²¡æœ‰ä»£ç å—äº†
        
        # [Step 4] æ¸…ç†å¤šä½™ç©ºè¡Œ
        new_content = re.sub(r'\n{3,}', '\n\n', new_content)

        return new_content.strip()
    
    def plan_word_count(self, total_words: int, outline_list: List[str]) -> Dict[str, Dict]:
        outline_str = "\n".join(outline_list)
        prompt = get_word_distribution_prompt(total_words, outline_str)
        
        try:
            response = self.main_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼è¾“å‡º JSON çš„å­¦æœ¯è§„åˆ’å¸ˆã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                stream=False,
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content.strip()
            if content.startswith("```"): content = re.sub(r'```json|```', '', content).strip()
            
            try:
                raw_map = json.loads(content)
            except json.JSONDecodeError:
                return {}

            standardized_map = {}
            for k, v in raw_map.items():
                if "total" in k.lower(): continue
                if isinstance(v, dict):
                    w = int(v.get('words', 0))
                    d = v.get('needs_data', False)
                    if isinstance(d, str): d = d.lower() == 'true'
                    standardized_map[k] = {"words": w, "needs_data": d}
                elif isinstance(v, (int, float)):
                    standardized_map[k] = {"words": int(v), "needs_data": False}
            
            current_total = sum(item['words'] for item in standardized_map.values())
            if current_total == 0: return standardized_map

            ratio = total_words / current_total
            final_map = {}
            for k, v in standardized_map.items():
                final_map[k] = {"words": int(v['words'] * ratio), "needs_data": v['needs_data']}
            
            # è¯¯å·®ä¿®æ­£
            new_total = sum(item['words'] for item in final_map.values())
            diff = total_words - new_total
            if diff != 0 and final_map:
                max_key = max(final_map, key=lambda k: final_map[k]['words'])
                final_map[max_key]['words'] += diff
                
            return final_map
        except Exception as e:
            print(f"Plan error: {e}")
            return {}